<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Stefan Daume">
  <title>Structural Topic Modeling with R</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./reveal.js-3.6.0/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="./custom_highlight.js-9.12.0/styles/zenburn.css">
  <script src="./custom_highlight.js-9.12.0/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <link rel="stylesheet" href="./reveal.js-3.6.0/css/theme/white.css" id="theme">
  <link rel="stylesheet" href="./css/mycustom.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? './reveal.js-3.6.0/css/print/pdf.css' : './reveal.js-3.6.0/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="./reveal.js-3.6.0/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Structural Topic Modeling with R</h1>
  <p class="author">Stefan Daume</p>
  <p class="date">11. April 2025</p>
</section>

<section id="section" class="slide level2 hideslideheader" data-background="#061C30">
<h2> </h2>
<div style="display:table;width:100%;table-layout: fixed;">
<div class="title-without-logo" style="display:table-cell;width:100%;padding-right:3%;padding-left:3%;vertical-align:middle;">
<p>SRC 2024/25 PhD course ‘Data Science for Sustainable Development’</p>
<p>Structural Topic Modeling with R</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
</div>
</div>
<div style="display:table;width:100%;table-layout: fixed;">
<div class="mytitlepage linksection" style="display:table-cell;width:30%;padding-left:3%;vertical-align:bottom;">
<p><em><a href="https://scitingly.net/" class="uri">https://scitingly.net/</a></em></p>
<p><em><a href="mailto:stefan.daume@su.se" class="email">stefan.daume@su.se</a></em></p>
</div>
<div class="mytitlepage authorsection" style="display:table-cell;width:70%;padding-right:3%;">
<p>  <strong>Stefan Daume</strong></p>
<p><em><a href="https://www.stockholmresilience.org/meet-our-team/staff/2021-01-27-daume.html">Stockholm Resilience Centre, Stockholm University</a></em></p>
<p>&amp; <em><a href="https://beijer.kva.se/programmes/complexity/">Beijer Institute of Ecological Economics</a></em></p>
<p> </p>
<p><em>11. April 2025</em></p>
</div>
</div>
</section>
<section><section id="text-as-data---basic-text-mining" class="title-slide slide level1"><h1>“Text as data” - Basic text mining</h1></section><section id="text-mining-packages" class="slide level2">
<h2>Text mining packages</h2>
<p>Basic packages:</p>
<ul>
<li>tidytext</li>
<li>stringr</li>
<li>dplyr</li>
<li>tidyr</li>
<li>(SnowballC)</li>
<li>(spacyr)</li>
<li>(textdata)</li>
</ul>
</section><section id="basic-text-mining-steps" class="slide level2">
<h2>Basic text mining steps</h2>
<ol type="1">
<li>get text (e.g., via gutenbergr)</li>
<li>tidy</li>
<li>tokenize</li>
<li>transform</li>
<li>(annotate)</li>
<li>analyze</li>
</ol>
</section><section id="basic-analysis-get-text-tidy-count" class="slide level2">
<h2>Basic analysis: get text, tidy, count</h2>
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get &quot;mystery&quot; text
book &lt;- gutenberg_download(c(244))

# books are lines of text with associated book ID
# tibble [4,737 × 2] (S3: tbl_df/tbl/data.frame)
#  $ gutenberg_id: int [1:4737] 244 244 244  ...
#  $ text        : chr [1:4737] &quot;&quot; &quot;&quot; &quot;&quot; ...

# tidy the text into individual words
# also lowercases and remove punctuation
tidy_book &lt;- book %&gt;%
  unnest_tokens(output = word, input = text)

# count the word/term frequency
word_count &lt;- tidy_book %&gt;%
  count(word, sort = TRUE)</code></pre>
<aside class="notes">
<ul>
<li>books from project gutenberg are returned as dataframes/tibbles with two columns that provide the text per line and the associated book ID</li>
<li><code>unnest_tokens()</code> both tokenizes and tidys the text (i.e., whitespace, punctuation is removed, the tokens are transformed to lowercase)<br />
</li>
</ul>
</aside>
</section><section id="most-frequent-words" class="slide level2">
<h2>Most frequent words</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:60%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get &quot;mystery&quot; text
book &lt;- gutenberg_download(c(244))

# tidy the text into individual words
# also lowercases and removes punctuation
tidy_book &lt;- book %&gt;%
  unnest_tokens(output = word, input = text)

# count the word/term frequency
word_count &lt;- tidy_book %&gt;%
  count(word, sort = TRUE)</code></pre>
</div>
<div style="display:table-cell;width:40%;padding-left:5%;text-align:left;vertical-align:top;">
<div id="ensxouokkw" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#ensxouokkw table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#ensxouokkw thead, #ensxouokkw tbody, #ensxouokkw tfoot, #ensxouokkw tr, #ensxouokkw td, #ensxouokkw th {
  border-style: none;
}

#ensxouokkw p {
  margin: 0;
  padding: 0;
}

#ensxouokkw .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ensxouokkw .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#ensxouokkw .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ensxouokkw .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ensxouokkw .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ensxouokkw .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ensxouokkw .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ensxouokkw .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ensxouokkw .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ensxouokkw .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ensxouokkw .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ensxouokkw .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ensxouokkw .gt_spanner_row {
  border-bottom-style: hidden;
}

#ensxouokkw .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#ensxouokkw .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ensxouokkw .gt_from_md > :first-child {
  margin-top: 0;
}

#ensxouokkw .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ensxouokkw .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ensxouokkw .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#ensxouokkw .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#ensxouokkw .gt_row_group_first td {
  border-top-width: 2px;
}

#ensxouokkw .gt_row_group_first th {
  border-top-width: 2px;
}

#ensxouokkw .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ensxouokkw .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#ensxouokkw .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#ensxouokkw .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ensxouokkw .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ensxouokkw .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ensxouokkw .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#ensxouokkw .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ensxouokkw .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ensxouokkw .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ensxouokkw .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ensxouokkw .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ensxouokkw .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ensxouokkw .gt_left {
  text-align: left;
}

#ensxouokkw .gt_center {
  text-align: center;
}

#ensxouokkw .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ensxouokkw .gt_font_normal {
  font-weight: normal;
}

#ensxouokkw .gt_font_bold {
  font-weight: bold;
}

#ensxouokkw .gt_font_italic {
  font-style: italic;
}

#ensxouokkw .gt_super {
  font-size: 65%;
}

#ensxouokkw .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#ensxouokkw .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#ensxouokkw .gt_indent_1 {
  text-indent: 5px;
}

#ensxouokkw .gt_indent_2 {
  text-indent: 10px;
}

#ensxouokkw .gt_indent_3 {
  text-indent: 15px;
}

#ensxouokkw .gt_indent_4 {
  text-indent: 20px;
}

#ensxouokkw .gt_indent_5 {
  text-indent: 25px;
}

#ensxouokkw .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#ensxouokkw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_title gt_font_normal" style>Mystery Book Word Count</td>
    </tr>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'>(10 most frequent terms)</span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="word">word</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="n">n</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="word" class="gt_row gt_left">the</td>
<td headers="n" class="gt_row gt_right">2536</td></tr>
    <tr><td headers="word" class="gt_row gt_left">and</td>
<td headers="n" class="gt_row gt_right">1356</td></tr>
    <tr><td headers="word" class="gt_row gt_left">of</td>
<td headers="n" class="gt_row gt_right">1213</td></tr>
    <tr><td headers="word" class="gt_row gt_left">to</td>
<td headers="n" class="gt_row gt_right">1093</td></tr>
    <tr><td headers="word" class="gt_row gt_left">a</td>
<td headers="n" class="gt_row gt_right">1010</td></tr>
    <tr><td headers="word" class="gt_row gt_left">i</td>
<td headers="n" class="gt_row gt_right">904</td></tr>
    <tr><td headers="word" class="gt_row gt_left">he</td>
<td headers="n" class="gt_row gt_right">795</td></tr>
    <tr><td headers="word" class="gt_row gt_left">in</td>
<td headers="n" class="gt_row gt_right">727</td></tr>
    <tr><td headers="word" class="gt_row gt_left">that</td>
<td headers="n" class="gt_row gt_right">655</td></tr>
    <tr><td headers="word" class="gt_row gt_left">his</td>
<td headers="n" class="gt_row gt_right">652</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<aside class="notes">
</aside>
</section><section id="exclude-stop-words" class="slide level2">
<h2>Exclude “stop words”</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:60%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get &quot;mystery&quot; text
book &lt;- gutenberg_download(c(244))

# tidy the text into individual words
# also lowercases and removes punctuation
tidy_book &lt;- book %&gt;%
  unnest_tokens(output = word, input = text)

# remove stopwords 
# (lexicon provided with tidytext)
word_count_filtered &lt;- tidy_book %&gt;%
  anti_join(stop_words, by = &quot;word&quot;) %&gt;%
  count(word, sort = TRUE)</code></pre>
</div>
<div style="display:table-cell;width:40%;padding-left:5%;text-align:left;vertical-align:top;">
<div id="aaordfrlxb" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#aaordfrlxb table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#aaordfrlxb thead, #aaordfrlxb tbody, #aaordfrlxb tfoot, #aaordfrlxb tr, #aaordfrlxb td, #aaordfrlxb th {
  border-style: none;
}

#aaordfrlxb p {
  margin: 0;
  padding: 0;
}

#aaordfrlxb .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#aaordfrlxb .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#aaordfrlxb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#aaordfrlxb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#aaordfrlxb .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#aaordfrlxb .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#aaordfrlxb .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#aaordfrlxb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#aaordfrlxb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#aaordfrlxb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#aaordfrlxb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#aaordfrlxb .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#aaordfrlxb .gt_spanner_row {
  border-bottom-style: hidden;
}

#aaordfrlxb .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#aaordfrlxb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#aaordfrlxb .gt_from_md > :first-child {
  margin-top: 0;
}

#aaordfrlxb .gt_from_md > :last-child {
  margin-bottom: 0;
}

#aaordfrlxb .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#aaordfrlxb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#aaordfrlxb .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#aaordfrlxb .gt_row_group_first td {
  border-top-width: 2px;
}

#aaordfrlxb .gt_row_group_first th {
  border-top-width: 2px;
}

#aaordfrlxb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#aaordfrlxb .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#aaordfrlxb .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#aaordfrlxb .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#aaordfrlxb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#aaordfrlxb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#aaordfrlxb .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#aaordfrlxb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#aaordfrlxb .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#aaordfrlxb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#aaordfrlxb .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#aaordfrlxb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#aaordfrlxb .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#aaordfrlxb .gt_left {
  text-align: left;
}

#aaordfrlxb .gt_center {
  text-align: center;
}

#aaordfrlxb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#aaordfrlxb .gt_font_normal {
  font-weight: normal;
}

#aaordfrlxb .gt_font_bold {
  font-weight: bold;
}

#aaordfrlxb .gt_font_italic {
  font-style: italic;
}

#aaordfrlxb .gt_super {
  font-size: 65%;
}

#aaordfrlxb .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#aaordfrlxb .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#aaordfrlxb .gt_indent_1 {
  text-indent: 5px;
}

#aaordfrlxb .gt_indent_2 {
  text-indent: 10px;
}

#aaordfrlxb .gt_indent_3 {
  text-indent: 15px;
}

#aaordfrlxb .gt_indent_4 {
  text-indent: 20px;
}

#aaordfrlxb .gt_indent_5 {
  text-indent: 25px;
}

#aaordfrlxb .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#aaordfrlxb div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_title gt_font_normal" style>Sample Stop Words</td>
    </tr>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'>(dataset included in <code>tidytext</code>)</span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="word">word</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="lexicon">lexicon</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="word" class="gt_row gt_left">a</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">a's</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">able</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">about</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">above</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">according</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">accordingly</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">across</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">actually</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
    <tr><td headers="word" class="gt_row gt_left">after</td>
<td headers="lexicon" class="gt_row gt_left">SMART</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li>the removed stopwords represent only 8.778626 % of the vocabulary (terms)</li>
<li>but 66.9513783% of all tokens</li>
</ul>
</aside>
</section><section id="filtered-word-count" class="slide level2">
<h2>Filtered word count</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:60%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get &quot;mystery&quot; text
book &lt;- gutenberg_download(c(244))

# tidy the text into individual words
# also lowercases and removes punctuation
tidy_book &lt;- book %&gt;%
  unnest_tokens(output = word, input = text)

# remove stopwords 
# (lexicon provided with tidytext)
word_count_filtered &lt;- tidy_book %&gt;%
  anti_join(stop_words, by = &quot;word&quot;) %&gt;%
  count(word, sort = TRUE)</code></pre>
</div>
<div style="display:table-cell;width:40%;padding-left:5%;text-align:left;vertical-align:top;">
<div id="uqcdpeishl" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#uqcdpeishl table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#uqcdpeishl thead, #uqcdpeishl tbody, #uqcdpeishl tfoot, #uqcdpeishl tr, #uqcdpeishl td, #uqcdpeishl th {
  border-style: none;
}

#uqcdpeishl p {
  margin: 0;
  padding: 0;
}

#uqcdpeishl .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#uqcdpeishl .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#uqcdpeishl .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#uqcdpeishl .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#uqcdpeishl .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#uqcdpeishl .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uqcdpeishl .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#uqcdpeishl .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#uqcdpeishl .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#uqcdpeishl .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#uqcdpeishl .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#uqcdpeishl .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#uqcdpeishl .gt_spanner_row {
  border-bottom-style: hidden;
}

#uqcdpeishl .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#uqcdpeishl .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#uqcdpeishl .gt_from_md > :first-child {
  margin-top: 0;
}

#uqcdpeishl .gt_from_md > :last-child {
  margin-bottom: 0;
}

#uqcdpeishl .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#uqcdpeishl .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#uqcdpeishl .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#uqcdpeishl .gt_row_group_first td {
  border-top-width: 2px;
}

#uqcdpeishl .gt_row_group_first th {
  border-top-width: 2px;
}

#uqcdpeishl .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#uqcdpeishl .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#uqcdpeishl .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#uqcdpeishl .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uqcdpeishl .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#uqcdpeishl .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#uqcdpeishl .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#uqcdpeishl .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#uqcdpeishl .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uqcdpeishl .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#uqcdpeishl .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#uqcdpeishl .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#uqcdpeishl .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#uqcdpeishl .gt_left {
  text-align: left;
}

#uqcdpeishl .gt_center {
  text-align: center;
}

#uqcdpeishl .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#uqcdpeishl .gt_font_normal {
  font-weight: normal;
}

#uqcdpeishl .gt_font_bold {
  font-weight: bold;
}

#uqcdpeishl .gt_font_italic {
  font-style: italic;
}

#uqcdpeishl .gt_super {
  font-size: 65%;
}

#uqcdpeishl .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#uqcdpeishl .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#uqcdpeishl .gt_indent_1 {
  text-indent: 5px;
}

#uqcdpeishl .gt_indent_2 {
  text-indent: 10px;
}

#uqcdpeishl .gt_indent_3 {
  text-indent: 15px;
}

#uqcdpeishl .gt_indent_4 {
  text-indent: 20px;
}

#uqcdpeishl .gt_indent_5 {
  text-indent: 25px;
}

#uqcdpeishl .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#uqcdpeishl div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_title gt_font_normal" style>Mystery Book Word Count</td>
    </tr>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'>(10 most frequent terms <strong>without stopwords</strong>)</span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="word">word</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="n">n</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="word" class="gt_row gt_left">holmes</td>
<td headers="n" class="gt_row gt_right">97</td></tr>
    <tr><td headers="word" class="gt_row gt_left">time</td>
<td headers="n" class="gt_row gt_right">77</td></tr>
    <tr><td headers="word" class="gt_row gt_left">answered</td>
<td headers="n" class="gt_row gt_right">59</td></tr>
    <tr><td headers="word" class="gt_row gt_left">eyes</td>
<td headers="n" class="gt_row gt_right">59</td></tr>
    <tr><td headers="word" class="gt_row gt_left">hand</td>
<td headers="n" class="gt_row gt_right">57</td></tr>
    <tr><td headers="word" class="gt_row gt_left">ferrier</td>
<td headers="n" class="gt_row gt_right">56</td></tr>
    <tr><td headers="word" class="gt_row gt_left">found</td>
<td headers="n" class="gt_row gt_right">55</td></tr>
    <tr><td headers="word" class="gt_row gt_left">hope</td>
<td headers="n" class="gt_row gt_right">55</td></tr>
    <tr><td headers="word" class="gt_row gt_left">drebber</td>
<td headers="n" class="gt_row gt_right">53</td></tr>
    <tr><td headers="word" class="gt_row gt_left">sherlock</td>
<td headers="n" class="gt_row gt_right">52</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</section><section id="tokens-can-be-more-than-words" class="slide level2">
<h2>Tokens can be more than words</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:70%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get &quot;mystery&quot; text
book &lt;- gutenberg_download(c(244))

# ngrams as tokens
tidy_ngrams &lt;- book %&gt;%
  unnest_tokens(bigram, text, 
                token = &quot;ngrams&quot;, n = 2,
                collapse = c(&quot;gutenberg_id&quot;)) %&gt;%
  filter(!is.na(bigram)) %&gt;%
  count(bigram, sort = TRUE)</code></pre>
</div>
<div style="display:table-cell;width:30%;padding-left:5%;text-align:left;vertical-align:top;">
<div id="sbdlaopmvo" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#sbdlaopmvo table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#sbdlaopmvo thead, #sbdlaopmvo tbody, #sbdlaopmvo tfoot, #sbdlaopmvo tr, #sbdlaopmvo td, #sbdlaopmvo th {
  border-style: none;
}

#sbdlaopmvo p {
  margin: 0;
  padding: 0;
}

#sbdlaopmvo .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#sbdlaopmvo .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#sbdlaopmvo .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#sbdlaopmvo .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#sbdlaopmvo .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#sbdlaopmvo .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sbdlaopmvo .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#sbdlaopmvo .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#sbdlaopmvo .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#sbdlaopmvo .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#sbdlaopmvo .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#sbdlaopmvo .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#sbdlaopmvo .gt_spanner_row {
  border-bottom-style: hidden;
}

#sbdlaopmvo .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#sbdlaopmvo .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#sbdlaopmvo .gt_from_md > :first-child {
  margin-top: 0;
}

#sbdlaopmvo .gt_from_md > :last-child {
  margin-bottom: 0;
}

#sbdlaopmvo .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#sbdlaopmvo .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#sbdlaopmvo .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#sbdlaopmvo .gt_row_group_first td {
  border-top-width: 2px;
}

#sbdlaopmvo .gt_row_group_first th {
  border-top-width: 2px;
}

#sbdlaopmvo .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#sbdlaopmvo .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#sbdlaopmvo .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#sbdlaopmvo .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sbdlaopmvo .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#sbdlaopmvo .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#sbdlaopmvo .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#sbdlaopmvo .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#sbdlaopmvo .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sbdlaopmvo .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#sbdlaopmvo .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#sbdlaopmvo .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#sbdlaopmvo .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#sbdlaopmvo .gt_left {
  text-align: left;
}

#sbdlaopmvo .gt_center {
  text-align: center;
}

#sbdlaopmvo .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#sbdlaopmvo .gt_font_normal {
  font-weight: normal;
}

#sbdlaopmvo .gt_font_bold {
  font-weight: bold;
}

#sbdlaopmvo .gt_font_italic {
  font-style: italic;
}

#sbdlaopmvo .gt_super {
  font-size: 65%;
}

#sbdlaopmvo .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#sbdlaopmvo .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#sbdlaopmvo .gt_indent_1 {
  text-indent: 5px;
}

#sbdlaopmvo .gt_indent_2 {
  text-indent: 10px;
}

#sbdlaopmvo .gt_indent_3 {
  text-indent: 15px;
}

#sbdlaopmvo .gt_indent_4 {
  text-indent: 20px;
}

#sbdlaopmvo .gt_indent_5 {
  text-indent: 25px;
}

#sbdlaopmvo .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#sbdlaopmvo div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_title gt_font_normal" style><span class='gt_from_md'>Mystery Book <em>n-gram</em> Count</span></td>
    </tr>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'>(10 most frequent terms)</span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="bigram">bigram</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="n">n</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="bigram" class="gt_row gt_left">of the</td>
<td headers="n" class="gt_row gt_right">302</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">in the</td>
<td headers="n" class="gt_row gt_right">210</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">to the</td>
<td headers="n" class="gt_row gt_right">136</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">to be</td>
<td headers="n" class="gt_row gt_right">98</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">it was</td>
<td headers="n" class="gt_row gt_right">95</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">he had</td>
<td headers="n" class="gt_row gt_right">94</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">and the</td>
<td headers="n" class="gt_row gt_right">89</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">upon the</td>
<td headers="n" class="gt_row gt_right">88</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">at the</td>
<td headers="n" class="gt_row gt_right">85</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">he was</td>
<td headers="n" class="gt_row gt_right">83</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li>typically, in text analysis, individual words are used as tokens</li>
<li>but what constitutes a relevant basic unit of information can vary</li>
<li>sometimes, n-grams (multiple successive words) could be the tokens to analyse</li>
</ul>
</aside>
</section><section id="the-games-afoot" class="slide level2">
<h2>“The game’s afoot …”</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:70%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get &quot;mystery&quot; text
book &lt;- gutenberg_download(c(244))

# ngrams as tokens (stop words filtered)
tidy_ngrams_filtered &lt;- book %&gt;%
  unnest_tokens(bigram, text, 
                token = &quot;ngrams&quot;, n = 2,
                collapse = c(&quot;gutenberg_id&quot;)) %&gt;%
  filter(!is.na(bigram)) %&gt;%
  tidyr::separate(bigram, c(&quot;token1&quot;, &quot;token2&quot;), sep = &quot; &quot;) %&gt;%
  anti_join(by = c(&quot;token1&quot; = &quot;word&quot;), stop_words) %&gt;%
  anti_join(by = c(&quot;token2&quot; = &quot;word&quot;), stop_words) %&gt;%
  tidyr::unite(bigram, token1, token2, sep = &quot; &quot;)

bigram_count &lt;- tidy_ngrams_filtered %&gt;%
  count(bigram, sort = TRUE)</code></pre>
</div>
<div style="display:table-cell;width:30%;padding-left:5%;text-align:left;vertical-align:top;">
<div id="udadfqmzqt" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#udadfqmzqt table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#udadfqmzqt thead, #udadfqmzqt tbody, #udadfqmzqt tfoot, #udadfqmzqt tr, #udadfqmzqt td, #udadfqmzqt th {
  border-style: none;
}

#udadfqmzqt p {
  margin: 0;
  padding: 0;
}

#udadfqmzqt .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#udadfqmzqt .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#udadfqmzqt .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#udadfqmzqt .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#udadfqmzqt .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#udadfqmzqt .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#udadfqmzqt .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#udadfqmzqt .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#udadfqmzqt .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#udadfqmzqt .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#udadfqmzqt .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#udadfqmzqt .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#udadfqmzqt .gt_spanner_row {
  border-bottom-style: hidden;
}

#udadfqmzqt .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#udadfqmzqt .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#udadfqmzqt .gt_from_md > :first-child {
  margin-top: 0;
}

#udadfqmzqt .gt_from_md > :last-child {
  margin-bottom: 0;
}

#udadfqmzqt .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#udadfqmzqt .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#udadfqmzqt .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#udadfqmzqt .gt_row_group_first td {
  border-top-width: 2px;
}

#udadfqmzqt .gt_row_group_first th {
  border-top-width: 2px;
}

#udadfqmzqt .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#udadfqmzqt .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#udadfqmzqt .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#udadfqmzqt .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#udadfqmzqt .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#udadfqmzqt .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#udadfqmzqt .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#udadfqmzqt .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#udadfqmzqt .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#udadfqmzqt .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#udadfqmzqt .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#udadfqmzqt .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#udadfqmzqt .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#udadfqmzqt .gt_left {
  text-align: left;
}

#udadfqmzqt .gt_center {
  text-align: center;
}

#udadfqmzqt .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#udadfqmzqt .gt_font_normal {
  font-weight: normal;
}

#udadfqmzqt .gt_font_bold {
  font-weight: bold;
}

#udadfqmzqt .gt_font_italic {
  font-style: italic;
}

#udadfqmzqt .gt_super {
  font-size: 65%;
}

#udadfqmzqt .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#udadfqmzqt .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#udadfqmzqt .gt_indent_1 {
  text-indent: 5px;
}

#udadfqmzqt .gt_indent_2 {
  text-indent: 10px;
}

#udadfqmzqt .gt_indent_3 {
  text-indent: 15px;
}

#udadfqmzqt .gt_indent_4 {
  text-indent: 20px;
}

#udadfqmzqt .gt_indent_5 {
  text-indent: 25px;
}

#udadfqmzqt .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#udadfqmzqt div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_title gt_font_normal" style><span class='gt_from_md'>Mystery Book <em>n-gram</em> Count</span></td>
    </tr>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'>(10 most frequent n-grams <br> <strong>without items containing a stop word</strong>)</span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="bigram">bigram</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="n">n</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="bigram" class="gt_row gt_left">sherlock holmes</td>
<td headers="n" class="gt_row gt_right">52</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">jefferson hope</td>
<td headers="n" class="gt_row gt_right">34</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">john ferrier</td>
<td headers="n" class="gt_row gt_right">25</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">brixton road</td>
<td headers="n" class="gt_row gt_right">13</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">joseph stangerson</td>
<td headers="n" class="gt_row gt_right">10</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">salt lake</td>
<td headers="n" class="gt_row gt_right">10</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">lake city</td>
<td headers="n" class="gt_row gt_right">9</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">lucy ferrier</td>
<td headers="n" class="gt_row gt_right">9</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">baker street</td>
<td headers="n" class="gt_row gt_right">6</td></tr>
    <tr><td headers="bigram" class="gt_row gt_left">lauriston gardens</td>
<td headers="n" class="gt_row gt_right">6</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li>typically, in text analysis, individual words are used as tokens</li>
<li>but what constitutes a relevant basic unit of information can vary</li>
<li>sometimes, n-grams (multiple successive words) could be the tokens to analyse</li>
</ul>
</aside>
</section><section id="further-options-sentiment-analysis" class="slide level2">
<h2>Further options: Sentiment Analysis</h2>
<div id="kopjzjomoz" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#kopjzjomoz table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#kopjzjomoz thead, #kopjzjomoz tbody, #kopjzjomoz tfoot, #kopjzjomoz tr, #kopjzjomoz td, #kopjzjomoz th {
  border-style: none;
}

#kopjzjomoz p {
  margin: 0;
  padding: 0;
}

#kopjzjomoz .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#kopjzjomoz .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#kopjzjomoz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#kopjzjomoz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#kopjzjomoz .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#kopjzjomoz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#kopjzjomoz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#kopjzjomoz .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#kopjzjomoz .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#kopjzjomoz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#kopjzjomoz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#kopjzjomoz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#kopjzjomoz .gt_spanner_row {
  border-bottom-style: hidden;
}

#kopjzjomoz .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#kopjzjomoz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#kopjzjomoz .gt_from_md > :first-child {
  margin-top: 0;
}

#kopjzjomoz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#kopjzjomoz .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#kopjzjomoz .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#kopjzjomoz .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#kopjzjomoz .gt_row_group_first td {
  border-top-width: 2px;
}

#kopjzjomoz .gt_row_group_first th {
  border-top-width: 2px;
}

#kopjzjomoz .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#kopjzjomoz .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#kopjzjomoz .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#kopjzjomoz .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#kopjzjomoz .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#kopjzjomoz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#kopjzjomoz .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#kopjzjomoz .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#kopjzjomoz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#kopjzjomoz .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#kopjzjomoz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#kopjzjomoz .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#kopjzjomoz .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#kopjzjomoz .gt_left {
  text-align: left;
}

#kopjzjomoz .gt_center {
  text-align: center;
}

#kopjzjomoz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#kopjzjomoz .gt_font_normal {
  font-weight: normal;
}

#kopjzjomoz .gt_font_bold {
  font-weight: bold;
}

#kopjzjomoz .gt_font_italic {
  font-style: italic;
}

#kopjzjomoz .gt_super {
  font-size: 65%;
}

#kopjzjomoz .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#kopjzjomoz .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#kopjzjomoz .gt_indent_1 {
  text-indent: 5px;
}

#kopjzjomoz .gt_indent_2 {
  text-indent: 10px;
}

#kopjzjomoz .gt_indent_3 {
  text-indent: 15px;
}

#kopjzjomoz .gt_indent_4 {
  text-indent: 20px;
}

#kopjzjomoz .gt_indent_5 {
  text-indent: 25px;
}

#kopjzjomoz .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#kopjzjomoz div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_title gt_font_normal" style><span class='gt_from_md'>Sentiment words and valence</span></td>
    </tr>
    <tr class="gt_heading">
      <td colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'><em>AFINN sentiment dictionary</em></span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="word">word</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="value">value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="word" class="gt_row gt_left">huge</td>
<td headers="value" class="gt_row gt_right">1</td></tr>
    <tr><td headers="word" class="gt_row gt_left">superb</td>
<td headers="value" class="gt_row gt_right">5</td></tr>
    <tr><td headers="word" class="gt_row gt_left">hooliganism</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">mischief</td>
<td headers="value" class="gt_row gt_right">-1</td></tr>
    <tr><td headers="word" class="gt_row gt_left">shared</td>
<td headers="value" class="gt_row gt_right">1</td></tr>
    <tr><td headers="word" class="gt_row gt_left">regretted</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">mock</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">grave</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">greenwashers</td>
<td headers="value" class="gt_row gt_right">-3</td></tr>
    <tr><td headers="word" class="gt_row gt_left">abducted</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
  </tbody>
  
  
</table>
</div>
</section><section id="frequent-sentiment-words" class="slide level2">
<h2>Frequent sentiment words</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:70%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get text
book &lt;- gutenberg_download(c(244))

# index line numbers and tidy
tidy_book_indexed &lt;- book %&gt;%
  mutate(line = row_number()) %&gt;%
  unnest_tokens(word, text)

# get a sentiment dictionary
afinn_dict &lt;- get_sentiments(&quot;afinn&quot;)

# most frequent words that overlap
# with the AFINN sentiment dictionary
sentiment_count &lt;- tidy_book_indexed %&gt;%
  anti_join(stop_words) %&gt;%
  count(word, sort = TRUE) %&gt;%
  inner_join(afinn_dict)</code></pre>
</div>
<div style="display:table-cell;width:30%;padding-left:5%;text-align:left;vertical-align:top;">
<div id="wdfgllqxdc" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#wdfgllqxdc table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#wdfgllqxdc thead, #wdfgllqxdc tbody, #wdfgllqxdc tfoot, #wdfgllqxdc tr, #wdfgllqxdc td, #wdfgllqxdc th {
  border-style: none;
}

#wdfgllqxdc p {
  margin: 0;
  padding: 0;
}

#wdfgllqxdc .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#wdfgllqxdc .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#wdfgllqxdc .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#wdfgllqxdc .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#wdfgllqxdc .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#wdfgllqxdc .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wdfgllqxdc .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#wdfgllqxdc .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#wdfgllqxdc .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#wdfgllqxdc .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#wdfgllqxdc .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#wdfgllqxdc .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#wdfgllqxdc .gt_spanner_row {
  border-bottom-style: hidden;
}

#wdfgllqxdc .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#wdfgllqxdc .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#wdfgllqxdc .gt_from_md > :first-child {
  margin-top: 0;
}

#wdfgllqxdc .gt_from_md > :last-child {
  margin-bottom: 0;
}

#wdfgllqxdc .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#wdfgllqxdc .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#wdfgllqxdc .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#wdfgllqxdc .gt_row_group_first td {
  border-top-width: 2px;
}

#wdfgllqxdc .gt_row_group_first th {
  border-top-width: 2px;
}

#wdfgllqxdc .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdfgllqxdc .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#wdfgllqxdc .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#wdfgllqxdc .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wdfgllqxdc .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdfgllqxdc .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#wdfgllqxdc .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#wdfgllqxdc .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#wdfgllqxdc .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wdfgllqxdc .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#wdfgllqxdc .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdfgllqxdc .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#wdfgllqxdc .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdfgllqxdc .gt_left {
  text-align: left;
}

#wdfgllqxdc .gt_center {
  text-align: center;
}

#wdfgllqxdc .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#wdfgllqxdc .gt_font_normal {
  font-weight: normal;
}

#wdfgllqxdc .gt_font_bold {
  font-weight: bold;
}

#wdfgllqxdc .gt_font_italic {
  font-style: italic;
}

#wdfgllqxdc .gt_super {
  font-size: 65%;
}

#wdfgllqxdc .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#wdfgllqxdc .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#wdfgllqxdc .gt_indent_1 {
  text-indent: 5px;
}

#wdfgllqxdc .gt_indent_2 {
  text-indent: 10px;
}

#wdfgllqxdc .gt_indent_3 {
  text-indent: 15px;
}

#wdfgllqxdc .gt_indent_4 {
  text-indent: 20px;
}

#wdfgllqxdc .gt_indent_5 {
  text-indent: 25px;
}

#wdfgllqxdc .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#wdfgllqxdc div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="3" class="gt_heading gt_title gt_font_normal" style><span class='gt_from_md'>Sentiment word count</span></td>
    </tr>
    <tr class="gt_heading">
      <td colspan="3" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style><span class='gt_from_md'>(10 most frequent words overlapping <br> with the AFINN dictionary)</span></td>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="word">word</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="n">n</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="value">value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="word" class="gt_row gt_left">hope</td>
<td headers="n" class="gt_row gt_right">55</td>
<td headers="value" class="gt_row gt_right">2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">cried</td>
<td headers="n" class="gt_row gt_right">49</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">death</td>
<td headers="n" class="gt_row gt_right">29</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">matter</td>
<td headers="n" class="gt_row gt_right">29</td>
<td headers="value" class="gt_row gt_right">1</td></tr>
    <tr><td headers="word" class="gt_row gt_left">doubt</td>
<td headers="n" class="gt_row gt_right">19</td>
<td headers="value" class="gt_row gt_right">-1</td></tr>
    <tr><td headers="word" class="gt_row gt_left">terrible</td>
<td headers="n" class="gt_row gt_right">19</td>
<td headers="value" class="gt_row gt_right">-3</td></tr>
    <tr><td headers="word" class="gt_row gt_left">murder</td>
<td headers="n" class="gt_row gt_right">18</td>
<td headers="value" class="gt_row gt_right">-2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">chance</td>
<td headers="n" class="gt_row gt_right">16</td>
<td headers="value" class="gt_row gt_right">2</td></tr>
    <tr><td headers="word" class="gt_row gt_left">leave</td>
<td headers="n" class="gt_row gt_right">16</td>
<td headers="value" class="gt_row gt_right">-1</td></tr>
    <tr><td headers="word" class="gt_row gt_left">crime</td>
<td headers="n" class="gt_row gt_right">15</td>
<td headers="value" class="gt_row gt_right">-3</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li>typically, in text analysis, individual words are used as tokens</li>
<li>but what constitutes a relevant basic unit of information can vary</li>
<li>sometimes, n-grams (multiple successive words) could be the tokens to analyse</li>
</ul>
</aside>
</section><section id="sentiment-trend" class="slide level2">
<h2>Sentiment trend</h2>
<div style="display:table;width:100%;table-layout:fixed;">
<div style="display:table-cell;width:50%;padding-right:5%;text-align:left;vertical-align:top;">
<pre class="r"><code>library(gutenbergr)
library(dplyr)
library(tidytext)

# get text
book &lt;- gutenberg_download(c(244))

# index line numbers and tidy
tidy_book_indexed &lt;- book %&gt;%
  mutate(line = row_number()) %&gt;%
  unnest_tokens(word, text)

# get a sentiment dictionary
afinn_dict &lt;- get_sentiments(&quot;afinn&quot;)

# mean sentiment summarized for 
# blocks of 50 consecutive lines
sentiment_trend &lt;- tidy_book_indexed %&gt;%
  inner_join(afinn_dict) %&gt;%
  group_by(index = line %/% 100) %&gt;%
  summarise(mean_sentiment = mean(value)) %&gt;%
  ungroup()

ggplot(sentiment_trend, 
       aes(x = index, 
           y = mean_sentiment)) +
  geom_point() +
  geom_line() +
  geom_smooth()</code></pre>
</div>
<div style="display:table-cell;width:50%;padding-left:5%;text-align:left;vertical-align:top;">
<p><img data-src="figures/unnamed-chunk-16-1.png" /></p>
</div>
</div>
<aside class="notes">
<ul>
<li>typically, in text analysis, individual words are used as tokens</li>
<li>but what constitutes a relevant basic unit of information can vary</li>
<li>sometimes, n-grams (multiple successive words) could be the tokens to analyse</li>
</ul>
</aside>
</section></section>
<section><section id="text-as-data---topic-modeling" class="title-slide slide level1"><h1>“Text as data” - Topic modeling</h1></section><section id="the-notion-of-latent-topics" class="slide level2">
<h2>The notion of “latent topics”</h2>
<p>Topic modeling applies <strong>unsupervised probabilistic classification</strong> to identify the <strong>latent</strong> (“hidden”) topics in a collection of documents.</p>
<aside class="notes">
<ul>
<li><strong>“Latent Topics”</strong>
<ul>
<li>e.g., if we review articles about urban sustainability, we would expect the major topics about <em>urban environments</em> and <em>sustainability</em> to be present</li>
<li>But how prevalent is each?</li>
<li>Which subtopics are emerging?</li>
<li>Which auxiliary topics (technology, social networks, AI)?</li>
<li>Are there unexpected topics?</li>
<li>In which combinations do these topics occur?</li>
</ul></li>
<li>How do we find these?
<ul>
<li>Manual analysis and categorisation. Possibly to create a labelled training data set for Machine Learning classifiers.</li>
<li>Or use unsupervised probabilistic classification, i.e. topic modeling.</li>
</ul></li>
<li><strong>NOTE:</strong>
<ul>
<li>Requires document collections!</li>
<li>Topics are defined as collections of words that frequently co-occur.</li>
</ul></li>
</ul>
</aside>
</section><section id="supervised-vs-unsupervised-learningclassification" class="slide level2">
<h2>Supervised vs unsupervised learning/classification</h2>
<p>Key difference: supervised learning requires <strong>labelled</strong> training data</p>
<aside class="notes">
<ul>
<li>Key takeaway: this has substantial practical and economical implications for research (different efforts, costs, teams)</li>
<li>add examples of effort processes</li>
</ul>
</aside>
</section><section id="why-topic-modeling" class="slide level2">
<h2>Why topic modeling?</h2>
<ul>
<li>summarize large text collections</li>
<li>discover “latent” topics</li>
<li>text-based (causal) inferences and testing social science theories</li>
</ul>
</section></section>
<section><section id="examples" class="title-slide slide level1"><h1>Examples</h1></section><section id="long-term-trends-in-climate-change-reports" class="slide level2">
<h2>Long-term trends in climate change reports</h2>
<p>A topography of climate change research <span class="citation" data-cites="CallaghanMinx_et_2020_NCC_10">(Callaghan, Minx, and Forster <a href="#/ref-CallaghanMinx_et_2020_NCC_10" role="doc-biblioref">2020</a>)</span></p>
<ul>
<li>more than 400.000 climate change publications analysed</li>
<li>over-representation of social sciences are in recent assessment reports</li>
<li>demand of more solution-oriented research</li>
</ul>
</section><section id="corporate-sustainability-reporting" class="slide level2">
<h2>Corporate sustainability reporting</h2>
<p>Analysis of 9,500 corporate sustainability reports (published 1999 to 2015) <span class="citation" data-cites="SzekelyBrocke_2017_PO_12">(Székely and Brocke <a href="#/ref-SzekelyBrocke_2017_PO_12" role="doc-biblioref">2017</a>)</span>:</p>
<ul>
<li>reports cover environmental, social, and economic sustainability</li>
<li>economic sustainability is of increasing importance</li>
<li>environmental sustainability is focused on emissions and energy</li>
<li>biodiversity receives little attention</li>
</ul>
<aside class="notes">
<ul>
<li>sustainability reports published between 1999 and 2015 for our study. We retrieved the PDF documents from the GRI website (<a href="http://database.globalreporting.org/search" class="uri">http://database.globalreporting.org/search</a>)</li>
</ul>
</aside>
</section><section id="climate-communication" class="slide level2">
<h2>Climate communication</h2>
<ul>
<li><strong>topic modeling</strong> of <strong>organizational climate communication</strong> to identify <strong>impact of corporate funding</strong> on climate polarization <span class="citation" data-cites="Farell_2016_PNAS_113">(Farrell <a href="#/ref-Farell_2016_PNAS_113" role="doc-biblioref">2016</a>)</span></li>
</ul>
<aside class="notes">
<ul>
<li>the last example is based on text and illustrates the use of the method we will focus on today</li>
</ul>
</aside>
</section><section id="perception-and-communication-of-policies" class="slide level2">
<h2>Perception and communication of policies</h2>
<p>Analysis of open-ended survey responses asking why carbon taxes are unfair <span class="citation" data-cites="PovitkinaCarlssonJagers_et_2021_GEC_70">(Povitkina et al. <a href="#/ref-PovitkinaCarlssonJagers_et_2021_GEC_70" role="doc-biblioref">2021</a>)</span>:</p>
<ul>
<li>impact of demographic factors on perceptions of fairness</li>
<li>implications for policy design</li>
</ul>
<aside class="notes">
<ul>
<li><p>Why are carbon taxes unfair? Disentangling public perceptions of fairness</p></li>
<li><p>mention that this (open-ended survey responses) is also the original usecase for STM</p></li>
<li><p><strong>several usecases that might relate to your own research and give an indication where topic models may be useful</strong></p></li>
<li><p><strong>also the reason we chose this techniques because we all deal with text in one way or another</strong></p></li>
</ul>
</aside>
</section></section>
<section><section id="topic-modeling-algorithm" class="title-slide slide level1"><h1>Topic modeling algorithm</h1></section><section id="how-does-it-work" class="slide level2">
<h2>How does it work?</h2>
<p>Generative model that reverses the assumed document generation process.</p>
</section><section id="generative-model" class="slide level2 xs-small-pg-text">
<h2>Generative model</h2>
<p><img src="images/topic_modelling_explained.jpg" width="60%" /></p>
<p>Illustration of the topic modeling process (<span class="citation" data-cites="DaumeAlbertEt2014_FORESTECOSYST_1">(Daume, Albert, and von Gadow <a href="#/ref-DaumeAlbertEt2014_FORESTECOSYST_1" role="doc-biblioref">2014</a>)</span> (adapted from <span class="citation" data-cites="Blei2012_COMMACM_55">(Blei <a href="#/ref-Blei2012_COMMACM_55" role="doc-biblioref">2012</a>)</span>)).</p>
</section><section id="topic-modelling-algorithms" class="slide level2">
<h2>Topic modelling algorithms</h2>
<ul>
<li>LSA - <a href="https://asistdl.onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-4571(199009)41:6%3C391::AID-ASI1%3E3.0.CO;2-9">Latent semantic analysis</a></li>
<li>LDA - Latent dirichlet allocation <span class="citation" data-cites="BleiNgEt2003_JMLR_3">(Blei, Ng, and Jordan <a href="#/ref-BleiNgEt2003_JMLR_3" role="doc-biblioref">2003</a>)</span></li>
<li>CTM - Correlated topic model <span class="citation" data-cites="BleiLafferty2007_AAS_1">(Blei and Lafferty <a href="#/ref-BleiLafferty2007_AAS_1" role="doc-biblioref">2007</a>)</span></li>
<li>STM - Structural topic model <span class="citation" data-cites="RobertsStewart_et_2019_JSTATS_91">(Roberts, Stewart, and Tingley <a href="#/ref-RobertsStewart_et_2019_JSTATS_91" role="doc-biblioref">2019</a>)</span></li>
</ul>
</section><section id="stm-vs-vanilla-lda" class="slide level2">
<h2>STM vs “vanilla LDA”</h2>
<ul>
<li>STM extends CTM (i.e. assumes that topics are correlated)</li>
<li>STM can incorporate arbitrary document meta-data into the topic model</li>
</ul>
</section><section id="basic-text-mining-concepts" class="slide level2">
<h2>Basic text mining concepts</h2>
<ul>
<li>documents</li>
<li>corpus</li>
<li>tokens</li>
<li>terms</li>
</ul>
</section><section id="basic-topic-modeling-steps" class="slide level2">
<h2>Basic Topic modeling steps</h2>
<ol type="1">
<li>get documents to analyse</li>
<li>preprocess</li>
<li>create a corpus</li>
<li>tokenize</li>
<li>create document-term/feature matrix</li>
<li><em>(evaluate alternative topic numbers)</em></li>
<li>decide on K, the number of topics, and fit a topic model</li>
<li><em>(validate semantic integrity of the topic model)</em></li>
<li>test impact of document meta-data on topics</li>
</ol>
</section><section id="r-packages-to-use" class="slide level2">
<h2>R packages to use</h2>
<ul>
<li>quanteda</li>
<li>tidytext</li>
<li>(snowballc)</li>
<li>(spacyr)</li>
<li>stringr</li>
<li>stm</li>
</ul>
</section></section>
<section><section id="structural-topic-modeling-applied" class="title-slide slide level1"><h1>Structural topic modeling applied</h1></section><section id="a-topic-model-of-covid-preprints" class="slide level2">
<h2>A Topic model of Covid preprints</h2>
<p>The following slides step through a detailed example of fitting a topic model to preprints on <a href="https://www.biorxiv.org/">bioRxiv</a> and <a href="https://www.medrxiv.org/">medRxiv</a> related to <em>Covid-19</em>.</p>
<p>R code and detailed examples are available here:</p>
<ul>
<li><strong>Code</strong>: <a href="https://github.com/sdaume/srcquantcourse" class="uri">https://github.com/sdaume/srcquantcourse</a></li>
<li><strong>Documentation</strong>: <a href="https://sdaume.github.io/srcquantcourse" class="uri">https://sdaume.github.io/srcquantcourse</a></li>
</ul>
</section><section id="motivation" class="slide level2">
<h2>Motivation</h2>
<ul>
<li>understand prevalent topics in preprints from <a href="https://www.biorxiv.org/">bioRxiv</a> and <a href="https://www.medrxiv.org/">medRxiv</a></li>
<li>explore the effect of document metadata (covariates), such as:
<ul>
<li>Which preprint server it was published on?</li>
<li>When it was published?</li>
<li>If it has been published after peer review?</li>
</ul></li>
</ul>
</section><section id="getting-data" class="slide level2">
<h2>Getting data</h2>
<p>Preprint data on <a href="https://www.biorxiv.org/">bioRxiv</a> and <a href="https://www.medrxiv.org/">medRxiv</a> can be retrieved via a <strong>public API</strong> with the help of the <a href="https://docs.ropensci.org/medrxivr/"><code>medrxivr</code></a> R package.</p>
</section><section id="preparing-preprint-metadata" class="slide level2">
<h2>Preparing preprint metadata</h2>
<pre class="r"><code>library(dplyr)
library(medrxivr)

# get publications from medRxiv and bioRxiv
pubs_biorxiv_raw &lt;- medrxivr::mx_api_content(server = &quot;biorxiv&quot;,
                                             #from_date = &quot;2019-01-01&quot;,
                                             to_date = &quot;2023-12-31&quot;)

pubs_medrxiv_raw &lt;- medrxivr::mx_api_content(server = &quot;medrxiv&quot;,
                                             #from_date = &quot;2019-01-01&quot;,
                                             to_date = &quot;2023-12-31&quot;)

pubs_biorxiv_raw &lt;- pubs_biorxiv_raw %&gt;%
  mutate(server = &quot;biorxiv&quot;)

pubs_medrxiv_raw &lt;- pubs_medrxiv_raw %&gt;%
  mutate(server = &quot;medrxiv&quot;)

preprints_raw &lt;- dplyr::bind_rows(pubs_biorxiv_raw, pubs_medrxiv_raw)

save(preprints_raw, file = &quot;./data-raw/preprints_raw.Rdata&quot;)</code></pre>
</section><section id="preprint-metadata" class="slide level2">
<h2>Preprint metadata</h2>
<pre><code>glimpse(preprints_raw)

Rows: 365,526
Columns: 16
$ doi                              &lt;chr&gt; &quot;10.1101/001891&quot;, &quot;10.1101/001867&quot;, &quot;10.1101…
$ title                            &lt;chr&gt; &quot;Population genomics of Saccharomyces cerevi…
$ authors                          &lt;chr&gt; &quot;Carlotta De Filippo;Monica Di Paola;Irene S…
$ author_corresponding             &lt;chr&gt; &quot;Duccio  Cavalieri&quot;, &quot;David  Morrison&quot;, &quot;Dav…
$ author_corresponding_institution &lt;chr&gt; &quot;Fondazione E. Mach (FEM)&quot;, &quot;Swedish Univers…
$ date                             &lt;chr&gt; &quot;2014-01-17&quot;, &quot;2014-01-17&quot;, &quot;2014-01-17&quot;, &quot;2…
$ version                          &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;,…
$ license                          &lt;chr&gt; &quot;cc_by_nc_nd&quot;, &quot;cc_by_nc&quot;, &quot;cc_by_nc&quot;, &quot;cc_b…
$ category                         &lt;chr&gt; &quot;Evolutionary Biology &quot;, &quot;Ecology &quot;, &quot;Molecu…
$ jatsxml                          &lt;chr&gt; &quot;https://www.biorxiv.org/content/early/2014/…
$ abstract                         &lt;chr&gt; &quot;The quest for the ecological niches of Sacc…
$ published                        &lt;chr&gt; &quot;NA&quot;, &quot;NA&quot;, &quot;NA&quot;, &quot;NA&quot;, &quot;10.1093/bioinformat…
$ node                             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…
$ link_page                        &lt;chr&gt; &quot;https://www.biorxiv.org/content/10.1101/001…
$ link_pdf                         &lt;chr&gt; &quot;https://www.biorxiv.org/content/10.1101/001…
$ server                           &lt;chr&gt; &quot;biorxiv&quot;, &quot;biorxiv&quot;, &quot;biorxiv&quot;, &quot;biorxiv&quot;, …</code></pre>
</section><section id="cleaning-filtering-and-annotating" class="slide level2">
<h2>Cleaning, filtering and annotating</h2>
<pre class="r"><code>library(dplyr)

preprints_cleaned &lt;- preprints_raw %&gt;%
  group_by(doi) %&gt;%
  filter(version == max(version)) %&gt;%
  ungroup() %&gt;%
  distinct(doi, .keep_all = TRUE)</code></pre>
</section><section id="cleaning-filtering-and-annotating-1" class="slide level2">
<h2>Cleaning, filtering and annotating</h2>
<pre class="r"><code>preprints &lt;- preprints_cleaned %&gt;%
  mutate(published = stringr::str_trim(published)) %&gt;%
  mutate(published = na_if(published, &quot;NA&quot;)) %&gt;%
  mutate(is_published = as.numeric(!is.na(published))) %&gt;%
  mutate(is_published = case_when(is_published == 1 ~ &quot;published&quot;,
                                  is_published == 0 ~ &quot;not published&quot;,
                                  TRUE ~ &quot;undefined&quot;)) %&gt;%
  mutate(year = lubridate::year(date)) %&gt;%
  filter(year &gt;= 2020 &amp; year &lt;= 2023) %&gt;% 
  select(doi, server, title, abstract, date, year, version, is_published)</code></pre>
</section><section id="cleaning-filtering-and-annotating-2" class="slide level2">
<h2>Cleaning, filtering and annotating</h2>
<pre class="r"><code>library(stringr)

keywords &lt;- c(&quot;sars-cov&quot;, &quot;covid&quot;)

search_pattern &lt;- stringr::regex(paste(keywords, collapse = &quot;|&quot;), 
                                 ignore_case = TRUE)

covid_preprints &lt;- preprints %&gt;%
  filter(stringr::str_detect(title, pattern = search_pattern) |
           stringr::str_detect(abstract, pattern = search_pattern))</code></pre>
</section><section id="preprocessing-the-documents-for-text-analysis" class="slide level2">
<h2>Preprocessing the documents for text analysis</h2>
<p>From text to data:</p>
<ul>
<li>create a corpus</li>
<li>tokenize and preprocess</li>
<li>create a document-feature matrix</li>
</ul>
</section><section id="preprocessing-the-documents-for-text-analysis-1" class="slide level2">
<h2>Preprocessing the documents for text analysis</h2>
<p>Text preprocessing choices could strongly influence the results of a text analysis!</p>
<p> </p>
<p>Choices need to be:</p>
<ul>
<li>thoroughly explained,</li>
<li>carefully evaluated and</li>
<li>ideally be based on theory (see <span class="citation" data-cites="DennySpirling_2018_PA_26">(Denny and Spirling <a href="#/ref-DennySpirling_2018_PA_26" role="doc-biblioref">2018</a>)</span>)</li>
</ul>
</section><section id="create-a-corpus" class="slide level2">
<h2>Create a corpus</h2>
<pre class="r"><code>library(quanteda)

pubs_corpus &lt;- covid_preprints %&gt;%
  quanteda::corpus(docid_field = &quot;doi&quot;, text_field = &quot;abstract&quot;)

# pubs_corpus
# Corpus consisting of 29,692 documents and 6 docvars.</code></pre>
<aside class="notes">
<p>First, we create a <strong>corpus</strong> object from the dataframe of preprints. The corpus is essentially a library of documents that will be used for the next steps. It specifies which variable should be used to uniquely identify documents and which variable holds the textual content (here the preprint <em>abstracts</em>) that should be processed.</p>
<p>Echoing the corpus will provide some basic information. All other variables in the original dataframe will be interpreted and included as document metadata (<em>‘docvars’</em>), which could later be included in the STM topic modelling process.</p>
</aside>
</section><section id="tokenize-and-preprocess" class="slide level2">
<h2>Tokenize and preprocess</h2>
<pre class="r"><code>pubs_tokens &lt;- pubs_corpus %&gt;%
  quanteda::tokens(remove_punct = TRUE,
                   remove_symbols = TRUE,
                   remove_numbers = TRUE,
                   remove_url = TRUE,
                   remove_separators = TRUE,
                   split_hyphens = TRUE) </code></pre>
<aside class="notes">
<p>For further analysis the corpus documents have to be <strong>tokenized</strong>, i.e. further processing the texts have to be broken into semantic units that are relevant for our analysis. The most common approach is to interpret each <em>word</em> (typically designated by whitespaces or punctuation) as a token. This is applied here as well. <code>quanteda</code> offers several alternative approaches. Instead of individual words, sequences of words (<em>n-grams</em>) could for example be used.</p>
<p>The tokenization method also provides several options for preprocessing and filtering the tokens. Here for example, while tokenizing, we will simultaneously remove punctuation, numbers, special symbols and URLs. Furthermore, we split words containing hyphens, a word like <em>social-ecological</em> will thus be split into two individual tokens (<em>social</em> and <em>ecological</em>).</p>
<p>The text preprocessing choices could strongly influence the results of a text analysis and should be thoroughly explained, carefully evaluated and ideally be based on theory (see <span class="citation" data-cites="DennySpirling_2018_PA_26">(Denny and Spirling <a href="#/ref-DennySpirling_2018_PA_26" role="doc-biblioref">2018</a>)</span>).</p>
</aside>
</section><section id="create-a-document-feature-matrix" class="slide level2">
<h2>Create a Document-feature matrix</h2>
<pre class="r"><code>pubs_dfm &lt;- pubs_tokens %&gt;%
  quanteda::dfm()</code></pre>
<aside class="notes">
<p>The <strong>tokens</strong> object is then used to create a <em>document-feature matrix</em>. For further statistical analysis this reduces the tokens to a matrix of documents (rows) and unique <strong>terms</strong> (columns) that counts the number of occurrences for each term in each document. <code>quanteda</code> captures this as <em>features</em> which supports more general options than <strong>terms</strong> (see the <code>quanteda</code> documentation for details).</p>
</aside>
</section><section id="filter-terms-and-documents" class="slide level2">
<h2>Filter terms and documents</h2>
<pre class="r"><code>pubs_dfm &lt;- pubs_dfm %&gt;%
  quanteda::dfm_remove(pattern = quanteda::stopwords(&quot;english&quot;)) #%&gt;%
  #quanteda::dfm_wordstem()</code></pre>
<pre><code># echo the result
&gt; pubs_dfm

Document-feature matrix of: 29,692 documents, 82,472 features (99.87% sparse) and 6 docvars.
                features
docs             nitric oxide synthesised three isoforms synthases viz nnos neurons enos
  10.1101/038398      6     6           1     1        1         1   1    1       2    1
  10.1101/058511      0     0           0     0        0         0   0    0       0    0
  10.1101/292979      0     0           0     2        0         0   0    0       0    0
  10.1101/402370      0     0           0     0        0         0   0    0       0    0
  10.1101/420737      0     0           0     0        0         0   0    0       0    0
  10.1101/596700      0     0           0     0        0         0   0    0       0    0
[ reached max_ndoc ... 29,686 more documents, reached max_nfeat ... 82,462 more features ]</code></pre>
<aside class="notes">
<p>This is followed by other (optional) processing and filtering steps. A common option for example — to reduce the size of the data or assist in the interpretation — is the removal of so-called <strong>stopwords</strong> (e.g. <em>“the”, “and”, “or”</em> etc).</p>
<p>A step omitted here is reducing words (terms) to their word stem. The stemming algorithm (several are available) reduces words to its word stem. The terms “universal”, “university” and “universe” would for example be reduced to the same word stem of “univers”; this example indicates that this approach may require careful consideration.</p>
<p>Stemming has the advantage that it could potentially reduce the size of the matrix substantially.</p>
</aside>
</section><section id="stemming" class="slide level2">
<h2>Stemming</h2>
<p><em>“Stemming”</em> will reduce the matrix, but could result in loosing semantic information.</p>
<p>For example: <strong>“universal”</strong>, <strong>“university”</strong> and <strong>“universe”</strong> all have the stem <strong>“univers”</strong>!</p>
</section><section id="more-filtering" class="slide level2">
<h2>More filtering</h2>
<pre class="r"><code>pubs_dfm &lt;- pubs_dfm %&gt;%
  quanteda::dfm_remove(min_nchar = 2) %&gt;%
  quanteda::dfm_trim(min_docfreq = 2, docfreq_type = &quot;count&quot;) %&gt;%
  quanteda::dfm_subset(quanteda::ntoken(.) &gt; 4)</code></pre>
<pre><code># echo the result
&gt; pubs_dfm

Document-feature matrix of: 29,691 documents, 37,093 features (99.72% sparse) and 6 docvars.
                features
docs             nitric oxide synthesised three isoforms synthases viz neurons enos endothelial
  10.1101/038398      6     6           1     1        1         1   1       2    1           2
  10.1101/058511      0     0           0     0        0         0   0       0    0           0
  10.1101/292979      0     0           0     2        0         0   0       0    0           0
  10.1101/402370      0     0           0     0        0         0   0       0    0           0
  10.1101/420737      0     0           0     0        0         0   0       0    0           0
  10.1101/596700      0     0           0     0        0         0   0       0    0           0
[ reached max_ndoc ... 29,685 more documents, reached max_nfeat ... 37,083 more features ]</code></pre>
<aside class="notes">
<p>Further options may be considered to reduce noise and/or the size of the matrix. The following code removes for example terms (or features) that consist only of one character, terms that do not appear in at least two different documents, and furthermore would remove documents that do not contain at least 5 tokens. In our example this drops one document and reduces the number of retained features by more than half.</p>
</aside>
</section><section id="fitting-the-stm-topic-model" class="slide level2">
<h2>Fitting the STM topic model</h2>
<pre class="r"><code>library(stm)

covid_stm_docs &lt;- quanteda::convert(pubs_dfm, to = &quot;stm&quot;)

covid_model_K20 &lt;- stm(documents = covid_stm_docs$documents,
                       vocab = covid_stm_docs$vocab,
                       data = covid_stm_docs$meta,
                       prevalence = ~ server * s(year),
                       K = 20,
                       verbose = TRUE,
                       seed = 9868467)</code></pre>
<aside class="notes">
<p>The key input to any topic modelling algorithm is the number of topics (<code>K</code>) that the model should be fit to, which we here set to 20 (see the separate document for a discussion on suitable choices for the number of topics).</p>
<p>Before fitting the topic model we convert the document-feature matrix into the native STM format. In order to fit a topic model with the <code>stm()</code> function we need the set of <code>documents</code>, the <code>vocabulary</code> of which these documents are composed and a dataframe specifying the values of all document meta-data variables (<code>data</code>) which can be used in the process as “covariates” that might influence the prevalence of topics in a document.</p>
<p>In the example below, we ask <code>stm</code> to incorporate the origin of the document (<code>server</code>) and the publication <code>year</code> when fitting the topic model. The argument <code>prevalence = ~ server * s(year)</code> expresses that we assume that the prevalence of topics in a document is influenced by these two variables, and that they also interact, i.e. we work with the hypothesis that different temporal trends could be expected for documents published on either of the two preprint servers<a href="#/fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>The consideration of covariates is optional. If omitted the model reduces to a <em>Correlated Topic Model</em> <span class="citation" data-cites="BleiLafferty2007_AAS_1 RobertsStewart_et_2019_JSTATS_91">(Blei and Lafferty <a href="#/ref-BleiLafferty2007_AAS_1" role="doc-biblioref">2007</a>; Roberts, Stewart, and Tingley <a href="#/ref-RobertsStewart_et_2019_JSTATS_91" role="doc-biblioref">2019</a>)</span>.</p>
<p>We also supply a <code>seed</code>, which allows to replicate the results of the topic modeling.</p>
</aside>
</section><section id="choosing-k" class="slide level2">
<h2>Choosing ‘K’</h2>
<p><img src="figures/unnamed-chunk-28-1.png" width="80%" /></p>
</section><section id="choosing-k-1" class="slide level2">
<h2>Choosing ‘K’</h2>
<p><img src="figures/unnamed-chunk-29-1.png" width="80%" /></p>
</section><section id="estimating-the-effect-of-document-covariates" class="slide level2">
<h2>Estimating the effect of document covariates</h2>
<pre class="r"><code>covid_effect_K20 &lt;- estimateEffect(1:20 ~ server * s(year),
                                   stmobj = covid_model_K20,
                                   metadata = covid_stm_docs$meta)</code></pre>
<aside class="notes">
<p>Once the model has converged we can estimate the effect of document covariates on the topic prevalence. The <code>estimateEffect()</code> function allows to run regressions based on the formula specified as the first argument. It is here identical to the formula used when fitting the topic model, and regressions are run for all 20 topics. The same metadata as used previously needs to be supplied for this function in addition to the topic model object.</p>
<p>This concludes fitting the model. The following sections step through a sample exploration of this topic model.</p>
</aside>
</section><section id="basic-topic-model-information" class="slide level2">
<h2>Basic topic model information</h2>
<pre class="r"><code>
plot(covid_model_K20, n = 5)</code></pre>
<p><img src="figures/unnamed-chunk-31-1.png" width="70%" /></p>
<aside class="notes">
<p>The topic model is defined by two matrices that capture probability distributions of topics over documents (<em>gamma</em> matrix) and words (or terms) over topics (<em>beta</em> matrix). We can start exploring these with some of the built-in functions of <code>stm</code>.</p>
<p>The <code>plot()</code> function plots a chart showing topic proportions for all topics in the model. A topic is identified by a unique ID (1-20) and in the plot below the five words (or terms) that have the highest probability of being associated with the given topic. This gives an early indication of the distinct latent topics in the analysed subset of preprints.</p>
</aside>
</section><section id="topic-words" class="slide level2">
<h2>Topic words</h2>
<pre class="r"><code>summary(covid_model_K20)
&gt;# A topic model with 20 topics, 29691 documents and a 37093 word dictionary.
&gt;# Topic 1 Top Words:
&gt;#       Highest Prob: model, can, covid, transmission, epidemic, data, disease 
&gt;#       FREX: npis, mathematical, compartmental, scenarios, seir, reproduction, sir 
&gt;#       Lift: 1we, abms, ao_scplowbstractc_scplowas, apt, artefact, asilv, asymptotically 
&gt;#       Score: distancing, social, epidemic, reproduction, npis, model, r0 
&gt;# Topic 2 Top Words:
&gt;#       Highest Prob: cov, sars, drug, antiviral, activity, drugs, covid 
&gt;#       FREX: src, figdir, o_linksmallfig, c_fig, m_fig, o_fig, gif 
&gt;#       Lift: k777, gif, pmmov, wwtps, 13k, 17k, 18k 
&gt;#       Score: mpro, antiviral, drug, inhibitors, protease, drugs, compounds 
&gt;# Topic 3 Top Words:
&gt;#       Highest Prob: covid, risk, age, mortality, ci, associated, years 
&gt;#       FREX: hispanic, ethnicity, pregnant, racial, black, smoking, preterm 
&gt;#       Lift: 65s, asmr, assault, backgroundethnic, backgroundracial, backgroundsocio, brunt 
&gt;#       Score: ci, age, women, mortality, ethnicity, aor, hispanic 
&gt;# Topic 4 Top Words:
&gt;#       Highest Prob: covid, health, pandemic, mental, social, study, survey 
&gt;#       FREX: loneliness, emotional, attitude, depression, insecurity, mental, anxiety 
&gt;#       Lift: insecurity, accelerometers, amhara, angry, anovas, asd, asleep 
&gt;#       Score: mental, anxiety, depression, respondents, social, psychological, students 
&gt;# Topic 5 Top Words:
&gt;#       Highest Prob: sars, cov, infection, testing, transmission, cases, children 
&gt;#       FREX: ifr, seroprevalence, schools, school, contacts, household, attack 
&gt;#       Lift: inmates, 19y, 35y, 39y, 9a, abidjan, addscovid 
&gt;#       Score: school, seroprevalence, children, schools, household, transmission, testing 
&gt;# Topic 6 Top Words:
&gt;#       Highest Prob: cov, sars, virus, viral, coronavirus, respiratory, infection 
&gt;#       FREX: bats, cats, deer, animals, covs, wildlife, hcov 
&gt;#       Lift: cats, 5x106, aav6, aegyptiacus, aethiops, affinis, agm 
&gt;#       Score: cov, sars, mice, rna, viruses, coronaviruses, animals 
&gt;# Topic 7 Top Words:
&gt;#       Highest Prob: patients, covid, hospital, disease, clinical, severe, admission 
&gt;#       FREX: acei, admission, arbs, admitted, icu, aki, aceis 
&gt;#       Lift: 1.1x109, 2020r1g1a1a01006229, 2l, 4.0x109, 40y, ahmad, ahrq 
&gt;#       Score: patients, admission, icu, hospital, admitted, ci, hospitalized 
&gt;# Topic 8 Top Words:
&gt;#       Highest Prob: covid, cases, countries, number, deaths, data, pandemic 
&gt;#       FREX: cfr, italy, cities, country, countries, fatality, china 
&gt;#       Lift: 1000m, 1th, 55th, abysmally, abyss, adhanom, adminstat 
&gt;#       Score: countries, cases, lockdown, deaths, country, cfr, daily 
&gt;# Topic 9 Top Words:
&gt;#       Highest Prob: protein, binding, spike, sars, cov, ace2, rbd 
&gt;#       FREX: conformational, cryo, conformation, glycans, conformations, nanobodies, residues 
&gt;#       Lift: 13c, 6lzg, 6m0j, 6vw1, 6vxx, aabpu, abdab 
&gt;#       Score: binding, rbd, protein, spike, ace2, proteins, epitopes 
&gt;# Topic 10 Top Words:
&gt;#       Highest Prob: data, can, learning, covid, using, model, based 
&gt;#       FREX: aerosol, n95, aerosols, respirators, decontamination, airborne, machine 
&gt;#       Lift: elastomeric, forehead, papr, radiomics, exhaled, singing, 0.3m 
&gt;#       Score: learning, masks, aerosol, machine, respirators, n95, mask 
&gt;# Topic 11 Top Words:
&gt;#       Highest Prob: vaccine, vaccination, covid, middle, vaccines, dot, dose 
&gt;#       FREX: hesitancy, dot, vaccinate, middle, hesitant, rollout, ve 
&gt;#       Lift: #949850, acceptant, adjrr, aesis, amparo, analysesthe, andersen 
&gt;#       Score: vaccination, vaccine, dot, booster, dose, vaccinated, middle 
&gt;# Topic 12 Top Words:
&gt;#       Highest Prob: studies, care, covid, health, research, data, pandemic 
&gt;#       FREX: reviews, telemedicine, preprints, scoping, articles, blacksquare, publications 
&gt;#       Lift: preprints, 1.2m, aas, abbreviating, accustomed, activists, advisor 
&gt;#       Score: review, care, services, articles, reviews, pubmed, service 
&gt;# Topic 13 Top Words:
&gt;#       Highest Prob: sars, cov, genome, mutations, sequencing, viral, variants 
&gt;#       FREX: phylogenetic, gisaid, clades, wgs, genomes, genomic, haplotype 
&gt;#       Lift: clades, snvs, 1.1.7s, 11083g, 14408c, 17del, 20a 
&gt;#       Score: mutations, genome, wastewater, genomes, sequences, sequencing, genomic 
&gt;# Topic 14 Top Words:
&gt;#       Highest Prob: cells, cell, sars, cov, expression, infection, ace2 
&gt;#       FREX: autophagy, mirnas, mirna, at2, ifns, ciliated, scrna 
&gt;#       Lift: 25hc, angiotensinogen, antagonizes, apcs, arf6, asgr1, at2s 
&gt;#       Score: cells, expression, ace2, cell, genes, epithelial, tmprss2 
&gt;# Topic 15 Top Words:
&gt;#       Highest Prob: antibody, sars, cov, antibodies, igg, responses, vaccine 
&gt;#       FREX: iga, bau, igg, humoral, immunogenicity, as03, reactogenicity 
&gt;#       Lift: 1x1011, 28d, 30ug, ad26cov2, addas03, adhu5, atellica 
&gt;#       Score: igg, antibody, antibodies, neutralizing, rbd, vaccine, spike 
&gt;# Topic 16 Top Words:
&gt;#       Highest Prob: sars, cov, pcr, samples, rt, test, testing 
&gt;#       FREX: ag, rdt, rdts, lod, rt, panbio, kits 
&gt;#       Lift: poct, cobas, panbio, #yomecorono, 1.6x104, 10min, 15min 
&gt;#       Score: rt, pcr, assay, samples, saliva, detection, assays 
&gt;# Topic 17 Top Words:
&gt;#       Highest Prob: variants, omicron, variant, delta, ba, cov, sars 
&gt;#       FREX: omicron, ba, xbb, subvariants, delta, bq, voc 
&gt;#       Lift: 1.5s, 129s2, 1f11, 2.86s, 3b8, 417n, 75d30121c11061 
&gt;#       Score: omicron, ba, variants, variant, delta, mutations, voc 
&gt;# Topic 18 Top Words:
&gt;#       Highest Prob: covid, patients, disease, severe, immune, inflammatory, associated 
&gt;#       FREX: autoantibodies, ipf, balf, neutrophils, il, fibrosis, autoantibody 
&gt;#       Lift: 18f, 24hr, a2ar, aab, actinobacteria, activin, adiponectin 
&gt;#       Score: inflammatory, il, patients, cytokine, inflammation, cytokines, endothelial 
&gt;# Topic 19 Top Words:
&gt;#       Highest Prob: patients, treatment, covid, group, days, day, trial 
&gt;#       FREX: placebo, randomized, hcq, soc, azithromycin, arm, tocilizumab 
&gt;#       Lift: 200mg, 400mg, 500mg, 600mg, 800mg, aureobasidium, ayush 
&gt;#       Score: placebo, hcq, trial, patients, randomized, tocilizumab, hydroxychloroquine 
&gt;# Topic 20 Top Words:
&gt;#       Highest Prob: covid, symptoms, long, workers, infection, participants, study 
&gt;#       FREX: hcws, taste, smell, hcw, fatigue, workers, headache 
&gt;#       Lift: chemesthetic, dirty, eyewear, firefighters, ohs, principality, psychophysical 
&gt;#       Score: symptoms, hcws, workers, participants, symptom, hcw, fatigue</code></pre>
<aside class="notes">
<p>The <code>summary()</code> function provides a more detailed view of the topics and can help to begin interpreting and labeling the 20 topics. Specifically, the output shows four different sets of words associated with a topic. <em>‘Highest Prob’</em> lists the words that have the highest probability of being associated with a topic. A comparison of different topics highlights that a term such as <em>covid</em> has a high probability for several topics. The list of <em>‘FREX’</em> words summarizes words that are frequent and exclusive in a topic, i.e. characterize a topic in comparison to other topics (consult <code>stm::labelTopics()</code> for details as well as <em>Lift</em> and <em>Score</em> word sets).</p>
</aside>
</section><section id="topic-document-gamma-distribution" class="slide level2">
<h2>Topic-document (‘gamma’) distribution</h2>
<pre class="r"><code># retrieve the &#39;gamma&#39; matrix
gamma &lt;- tidytext::tidy(covid_model_K20, matrix = &quot;gamma&quot;)

glimpse(gamma)
&gt;# Rows: 593,820
&gt;# Columns: 3
&gt;# $ document &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…
&gt;# $ topic    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
&gt;# $ gamma    &lt;dbl&gt; 0.001283143, 0.003547179, 0.003745510, 0.005495076, 0.0630417…</code></pre>
<aside class="notes">
<p>As mentioned, the topic model is defined by the <em>gamma</em> (distribution of topics over words) and <em>beta</em> (distribution of terms over topics) matrices. With the help of the <code>tidytext</code> package we can extract those into dataframes for a more detailed analysis.</p>
<p>Each row in the following dataframe lists the probability (<code>gamma</code>) of a given <code>topic</code> occurring in a given <code>document</code><a href="#/fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</aside>
</section><section id="term-topic-beta-distribution" class="slide level2">
<h2>Term-topic (‘beta’) distribution</h2>
<pre class="r"><code># retrieve the &#39;beta&#39; matrix
beta &lt;- tidytext::tidy(covid_model_K20, matrix = &quot;beta&quot;)

glimpse(beta)
&gt;# Rows: 741,860
&gt;# Columns: 3
&gt;# $ topic &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…
&gt;# $ term  &lt;chr&gt; &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;, &quot;#1&quot;…
&gt;# $ beta  &lt;dbl&gt; 1.874650e-112, 2.519509e-119, 1.248970e-118, 6.665355e-160, 3.21…</code></pre>
<aside class="notes">
<p>Similarly, the <em>beta</em> matrix (extracted into a dataframe) lists for each row the probability (<code>beta</code>) of a given <code>term</code> occurring in a given <code>topic</code>.</p>
<p>Starting with the <em>beta</em> matrix we can create word clouds to explore useful semantic labels for each topic.</p>
</aside>
</section><section id="understanding-and-labeling-topics" class="slide level2">
<h2>Understanding and labeling topics</h2>
<div class="figure">
<p><img src="figures/unnamed-chunk-35-1.png" alt="**Word clouds showing the 50 most probable terms for selected topics.** *FREX* terms are highlighted in orange. Words are scaled by normalized probability." width="80%" /></p>
<p class="caption">
<p><strong>Word clouds showing the 50 most probable terms for selected topics.</strong> <em>FREX</em> terms are highlighted in orange. Words are scaled by normalized probability.</p>
</p>
</div>
<aside class="notes">
<p>As mentioned previously <code>stm</code> can use the word probabilities to also compute <em>FREX</em> (frequent and exclusive) words per topic. Those can be retrieved with the <code>stm::labelTopics()</code> function, which returns ordered lists of the different word sets characterizing a topic. We can combine the information about <em>high probability</em> and <em>FREX</em> words to create word clouds for each topic, which might help to assign a summary label for each topic.</p>
<p>From the review of this combination of <em>FREX</em> and <em>high probability</em> terms distinct topics are emerging, such as: “epidemic models” (Topic 1), “vaccines” (Topic 11), “testing” (Topic 16), “virus variants” (Topic 17), “treatments” (Topic 2), “mortality risks” (Topic 3), “mental health” (Topic 4), “country-wise case reports” (Topic 8), “virus molecular structure” (Topic 9).</p>
<p>Deriving semantic labels will also benefit from a review of sample documents that are representative for certain topics, i.e. where the topic model assigns a high topic proportion of a given topic to the document. Furthermore, the consistency of assigned semantic labels should be checked prior to further analysis (see for example the <a href="https://github.com/gesistsa/oolong"><code>oolong</code> package</a> for a systematic approach).</p>
</aside>
</section><section id="covariate-effects" class="slide level2">
<h2>Covariate effects</h2>
<pre class="r"><code>
summary(covid_effect_K20)
&gt;# 
&gt;# Call:
&gt;# estimateEffect(formula = 1:20 ~ server * s(year), stmobj = covid_model_K20, 
&gt;#     metadata = covid_stm_docs$meta)
&gt;# 
&gt;# 
&gt;# Topic 1:
&gt;# 
&gt;# Coefficients:
&gt;#                          Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.0234503  0.0036678   6.394 1.64e-10 ***
&gt;# servermedrxiv           0.1239542  0.0042963  28.851  &lt; 2e-16 ***
&gt;# s(year)1               -0.0017746  0.0147722  -0.120    0.904    
&gt;# s(year)2               -0.0007821  0.0154516  -0.051    0.960    
&gt;# s(year)3                0.0083530  0.0067075   1.245    0.213    
&gt;# servermedrxiv:s(year)1 -0.0697548  0.0172531  -4.043 5.29e-05 ***
&gt;# servermedrxiv:s(year)2 -0.0964020  0.0189904  -5.076 3.87e-07 ***
&gt;# servermedrxiv:s(year)3 -0.0705496  0.0085297  -8.271  &lt; 2e-16 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 2:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.098657   0.002878  34.280  &lt; 2e-16 ***
&gt;# servermedrxiv          -0.085927   0.003146 -27.314  &lt; 2e-16 ***
&gt;# s(year)1               -0.019894   0.011321  -1.757   0.0789 .  
&gt;# s(year)2               -0.011340   0.013429  -0.844   0.3984    
&gt;# s(year)3               -0.028630   0.004508  -6.351 2.18e-10 ***
&gt;# servermedrxiv:s(year)1  0.021571   0.012568   1.716   0.0861 .  
&gt;# servermedrxiv:s(year)2  0.008326   0.014493   0.575   0.5656    
&gt;# servermedrxiv:s(year)3  0.030389   0.005235   5.805 6.49e-09 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 3:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.011083   0.002818   3.934 8.38e-05 ***
&gt;# servermedrxiv           0.053927   0.003293  16.376  &lt; 2e-16 ***
&gt;# s(year)1               -0.002551   0.011345  -0.225    0.822    
&gt;# s(year)2               -0.001965   0.011814  -0.166    0.868    
&gt;# s(year)3                0.001263   0.004848   0.261    0.794    
&gt;# servermedrxiv:s(year)1  0.014884   0.013778   1.080    0.280    
&gt;# servermedrxiv:s(year)2  0.014407   0.014958   0.963    0.335    
&gt;# servermedrxiv:s(year)3  0.029754   0.006490   4.584 4.57e-06 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 4:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.008861   0.003281   2.700  0.00693 ** 
&gt;# servermedrxiv           0.057703   0.003848  14.995  &lt; 2e-16 ***
&gt;# s(year)1                0.004713   0.013406   0.352  0.72518    
&gt;# s(year)2               -0.005223   0.013975  -0.374  0.70863    
&gt;# s(year)3                0.004505   0.005905   0.763  0.44550    
&gt;# servermedrxiv:s(year)1  0.020487   0.016568   1.237  0.21627    
&gt;# servermedrxiv:s(year)2 -0.004038   0.018078  -0.223  0.82324    
&gt;# servermedrxiv:s(year)3  0.020343   0.007726   2.633  0.00847 ** 
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 5:
&gt;# 
&gt;# Coefficients:
&gt;#                          Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             4.946e-03  2.312e-03   2.139   0.0325 *  
&gt;# servermedrxiv           5.426e-02  2.770e-03  19.588   &lt;2e-16 ***
&gt;# s(year)1               -6.267e-04  9.379e-03  -0.067   0.9467    
&gt;# s(year)2               -1.779e-05  9.852e-03  -0.002   0.9986    
&gt;# s(year)3                1.104e-03  4.119e-03   0.268   0.7886    
&gt;# servermedrxiv:s(year)1  2.590e-02  1.150e-02   2.251   0.0244 *  
&gt;# servermedrxiv:s(year)2 -1.610e-03  1.213e-02  -0.133   0.8944    
&gt;# servermedrxiv:s(year)3 -8.542e-03  5.360e-03  -1.594   0.1110    
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 6:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.148624   0.003870  38.407  &lt; 2e-16 ***
&gt;# servermedrxiv          -0.115794   0.004248 -27.257  &lt; 2e-16 ***
&gt;# s(year)1               -0.020989   0.013515  -1.553   0.1204    
&gt;# s(year)2               -0.049283   0.012151  -4.056 5.01e-05 ***
&gt;# s(year)3               -0.043745   0.006055  -7.225 5.15e-13 ***
&gt;# servermedrxiv:s(year)1  0.005698   0.015031   0.379   0.7047    
&gt;# servermedrxiv:s(year)2  0.035590   0.013826   2.574   0.0101 *  
&gt;# servermedrxiv:s(year)3  0.031013   0.006947   4.464 8.08e-06 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 7:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.010717   0.002948   3.635 0.000278 ***
&gt;# servermedrxiv           0.086049   0.003476  24.758  &lt; 2e-16 ***
&gt;# s(year)1               -0.003952   0.011575  -0.341 0.732765    
&gt;# s(year)2               -0.008054   0.012198  -0.660 0.509092    
&gt;# s(year)3               -0.003361   0.005144  -0.653 0.513487    
&gt;# servermedrxiv:s(year)1 -0.049451   0.014565  -3.395 0.000686 ***
&gt;# servermedrxiv:s(year)2 -0.019398   0.015722  -1.234 0.217259    
&gt;# servermedrxiv:s(year)3 -0.038502   0.006509  -5.916 3.34e-09 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 8:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.027222   0.003052   8.920  &lt; 2e-16 ***
&gt;# servermedrxiv           0.108727   0.003580  30.370  &lt; 2e-16 ***
&gt;# s(year)1               -0.012864   0.012458  -1.033  0.30180    
&gt;# s(year)2               -0.018301   0.012581  -1.455  0.14579    
&gt;# s(year)3               -0.017009   0.005244  -3.243  0.00118 ** 
&gt;# servermedrxiv:s(year)1 -0.088458   0.015019  -5.890 3.91e-09 ***
&gt;# servermedrxiv:s(year)2 -0.046560   0.015682  -2.969  0.00299 ** 
&gt;# servermedrxiv:s(year)3 -0.060294   0.006566  -9.183  &lt; 2e-16 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 9:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.170500   0.004569  37.320  &lt; 2e-16 ***
&gt;# servermedrxiv          -0.163953   0.004790 -34.228  &lt; 2e-16 ***
&gt;# s(year)1                0.017964   0.018966   0.947  0.34357    
&gt;# s(year)2               -0.034718   0.020021  -1.734  0.08291 .  
&gt;# s(year)3               -0.027962   0.006580  -4.250 2.15e-05 ***
&gt;# servermedrxiv:s(year)1 -0.010870   0.020060  -0.542  0.58791    
&gt;# servermedrxiv:s(year)2  0.032995   0.021816   1.512  0.13044    
&gt;# servermedrxiv:s(year)3  0.027871   0.007205   3.868  0.00011 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 10:
&gt;# 
&gt;# Coefficients:
&gt;#                          Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.0446992  0.0033211  13.459  &lt; 2e-16 ***
&gt;# servermedrxiv           0.0118201  0.0035957   3.287  0.00101 ** 
&gt;# s(year)1                0.0042737  0.0145266   0.294  0.76861    
&gt;# s(year)2                0.0001831  0.0132304   0.014  0.98896    
&gt;# s(year)3                0.0261619  0.0058634   4.462 8.15e-06 ***
&gt;# servermedrxiv:s(year)1 -0.0178567  0.0161482  -1.106  0.26882    
&gt;# servermedrxiv:s(year)2 -0.0303986  0.0154298  -1.970  0.04883 *  
&gt;# servermedrxiv:s(year)3 -0.0409439  0.0070558  -5.803 6.59e-09 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 11:
&gt;# 
&gt;# Coefficients:
&gt;#                        Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)            0.005036   0.002342   2.150  0.03154 *  
&gt;# servermedrxiv          0.008228   0.002678   3.073  0.00212 ** 
&gt;# s(year)1               0.010222   0.009882   1.034  0.30095    
&gt;# s(year)2               0.009921   0.010099   0.982  0.32594    
&gt;# s(year)3               0.006427   0.004262   1.508  0.13163    
&gt;# servermedrxiv:s(year)1 0.056923   0.011676   4.875 1.09e-06 ***
&gt;# servermedrxiv:s(year)2 0.073722   0.012328   5.980 2.26e-09 ***
&gt;# servermedrxiv:s(year)3 0.047034   0.005903   7.968 1.67e-15 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 12:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.021991   0.002862   7.683 1.61e-14 ***
&gt;# servermedrxiv           0.041948   0.003430  12.230  &lt; 2e-16 ***
&gt;# s(year)1               -0.008709   0.011175  -0.779    0.436    
&gt;# s(year)2               -0.005607   0.012058  -0.465    0.642    
&gt;# s(year)3               -0.002651   0.004899  -0.541    0.589    
&gt;# servermedrxiv:s(year)1 -0.006518   0.013868  -0.470    0.638    
&gt;# servermedrxiv:s(year)2  0.009374   0.015697   0.597    0.550    
&gt;# servermedrxiv:s(year)3  0.034861   0.006477   5.382 7.41e-08 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 13:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.104391   0.003127  33.381  &lt; 2e-16 ***
&gt;# servermedrxiv          -0.086349   0.003439 -25.106  &lt; 2e-16 ***
&gt;# s(year)1               -0.031628   0.015548  -2.034   0.0419 *  
&gt;# s(year)2               -0.027972   0.015169  -1.844   0.0652 .  
&gt;# s(year)3               -0.023314   0.005580  -4.178 2.94e-05 ***
&gt;# servermedrxiv:s(year)1  0.077860   0.018095   4.303 1.69e-05 ***
&gt;# servermedrxiv:s(year)2  0.028155   0.017013   1.655   0.0979 .  
&gt;# servermedrxiv:s(year)3  0.041091   0.006608   6.218 5.10e-10 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 14:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.124606   0.003387  36.787   &lt;2e-16 ***
&gt;# servermedrxiv          -0.112739   0.003582 -31.470   &lt;2e-16 ***
&gt;# s(year)1                0.004213   0.015040   0.280    0.779    
&gt;# s(year)2               -0.007591   0.015719  -0.483    0.629    
&gt;# s(year)3                0.007563   0.006329   1.195    0.232    
&gt;# servermedrxiv:s(year)1 -0.003055   0.015911  -0.192    0.848    
&gt;# servermedrxiv:s(year)2  0.005321   0.016728   0.318    0.750    
&gt;# servermedrxiv:s(year)3 -0.005104   0.007086  -0.720    0.471    
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 15:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.053537   0.003494  15.321  &lt; 2e-16 ***
&gt;# servermedrxiv          -0.027451   0.003956  -6.939 4.02e-12 ***
&gt;# s(year)1                0.044538   0.014783   3.013  0.00259 ** 
&gt;# s(year)2                0.024768   0.015587   1.589  0.11206    
&gt;# s(year)3                0.017697   0.006480   2.731  0.00632 ** 
&gt;# servermedrxiv:s(year)1  0.003863   0.017316   0.223  0.82345    
&gt;# servermedrxiv:s(year)2  0.033493   0.017854   1.876  0.06068 .  
&gt;# servermedrxiv:s(year)3 -0.003381   0.007605  -0.445  0.65659    
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 16:
&gt;# 
&gt;# Coefficients:
&gt;#                          Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.0531493  0.0034711  15.312  &lt; 2e-16 ***
&gt;# servermedrxiv           0.0176444  0.0040309   4.377 1.21e-05 ***
&gt;# s(year)1               -0.0492659  0.0130563  -3.773 0.000161 ***
&gt;# s(year)2               -0.0296669  0.0132919  -2.232 0.025625 *  
&gt;# s(year)3               -0.0278621  0.0058092  -4.796 1.63e-06 ***
&gt;# servermedrxiv:s(year)1  0.0605427  0.0150769   4.016 5.94e-05 ***
&gt;# servermedrxiv:s(year)2  0.0014582  0.0160846   0.091 0.927763    
&gt;# servermedrxiv:s(year)3 -0.0007419  0.0072247  -0.103 0.918214    
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 17:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.012479   0.002386   5.231 1.70e-07 ***
&gt;# servermedrxiv          -0.010812   0.002659  -4.066 4.80e-05 ***
&gt;# s(year)1                0.062697   0.011941   5.250 1.53e-07 ***
&gt;# s(year)2                0.167152   0.016155  10.346  &lt; 2e-16 ***
&gt;# s(year)3                0.074823   0.005294  14.134  &lt; 2e-16 ***
&gt;# servermedrxiv:s(year)1 -0.043824   0.013337  -3.286  0.00102 ** 
&gt;# servermedrxiv:s(year)2 -0.080067   0.018011  -4.445 8.80e-06 ***
&gt;# servermedrxiv:s(year)3 -0.038011   0.006068  -6.264 3.80e-10 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 18:
&gt;# 
&gt;# Coefficients:
&gt;#                         Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.055682   0.003078  18.092  &lt; 2e-16 ***
&gt;# servermedrxiv          -0.019892   0.003473  -5.727 1.03e-08 ***
&gt;# s(year)1                0.005546   0.012113   0.458  0.64706    
&gt;# s(year)2                0.004132   0.012775   0.323  0.74635    
&gt;# s(year)3                0.029360   0.005809   5.054 4.35e-07 ***
&gt;# servermedrxiv:s(year)1 -0.004441   0.014664  -0.303  0.76200    
&gt;# servermedrxiv:s(year)2 -0.004689   0.015397  -0.305  0.76070    
&gt;# servermedrxiv:s(year)3 -0.020595   0.006862  -3.001  0.00269 ** 
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 19:
&gt;# 
&gt;# Coefficients:
&gt;#                          Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             0.0135442  0.0026035   5.202 1.98e-07 ***
&gt;# servermedrxiv           0.0273503  0.0030238   9.045  &lt; 2e-16 ***
&gt;# s(year)1                0.0004532  0.0099641   0.045   0.9637    
&gt;# s(year)2               -0.0062710  0.0106365  -0.590   0.5555    
&gt;# s(year)3               -0.0030593  0.0043667  -0.701   0.4836    
&gt;# servermedrxiv:s(year)1 -0.0030182  0.0122192  -0.247   0.8049    
&gt;# servermedrxiv:s(year)2  0.0281305  0.0133232   2.111   0.0347 *  
&gt;# servermedrxiv:s(year)3  0.0027386  0.0057701   0.475   0.6351    
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&gt;# 
&gt;# 
&gt;# Topic 20:
&gt;# 
&gt;# Coefficients:
&gt;#                          Estimate Std. Error t value Pr(&gt;|t|)    
&gt;# (Intercept)             6.703e-03  1.964e-03   3.412 0.000646 ***
&gt;# servermedrxiv           3.145e-02  2.241e-03  14.030  &lt; 2e-16 ***
&gt;# s(year)1               -1.452e-03  7.669e-03  -0.189 0.849776    
&gt;# s(year)2               -6.112e-06  8.115e-03  -0.001 0.999399    
&gt;# s(year)3                4.811e-04  3.443e-03   0.140 0.888868    
&gt;# servermedrxiv:s(year)1  8.636e-03  9.703e-03   0.890 0.373448    
&gt;# servermedrxiv:s(year)2  1.282e-02  1.060e-02   1.209 0.226542    
&gt;# servermedrxiv:s(year)3  2.133e-02  4.686e-03   4.553 5.31e-06 ***
&gt;# ---
&gt;# Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<aside class="notes">
<p>A key feature of STM is the incorporation of document covariates into the topic model. In our example we considered the publication year and the preprint server as covariates that might influence the prevalence of a topic in a document. We also applied a regression for these covariates to the fit model, which were extracted with <code>stm::estimateEffect()</code>.</p>
<p>As a first exploration we can print the regression tables for all or selected topics.</p>
</aside>
</section><section id="publication-year" class="slide level2">
<h2>Publication year</h2>
<p><img src="figures/unnamed-chunk-38-1.png" width="70%" /></p>
<aside class="notes">
<p><code>stm</code> offers several built-in methods to explore the covariate effects visually. The visualization of the effect of preprint <em>publication year</em> on <em>expected topic proportions</em> confirm some trends that appear to match intuitively with different phases of the Covid-19 pandemic. Modelling the spread of infections (Topic 1) had a high relevance initially, but declined later, the same applies to (PCR-)testing (Topic 16), while vaccines (Topic 11) received limited coverage in earlier preprints, but became more important in later years as they were developed and distributed.</p>
</aside>
</section><section id="plotting-with-stm" class="slide level2">
<h2>Plotting with <code>stm</code></h2>
<pre class="r"><code>plot(covid_effect_K20,
     covariate = &quot;year&quot;,
     method = &quot;continuous&quot;,
     model = covid_model_K20,
     topics = c(1, 16, 11),
     xaxt = &quot;n&quot;,
     main = &#39;Effect of publication year on prevalence of Topic 1 (&quot;epidemic \nmodels&quot;), Topic 16 (&quot;testing&quot;) and Topic 11 (&quot;vaccines&quot;)&#39;,
     labeltype = &quot;prob&quot;,
     xlab = &quot;Publication year&quot;)
axis(1, at = c(&quot;2020&quot;,&quot;2021&quot;,&quot;2022&quot;,&quot;2023&quot;), labels = c(2020, 2021, 2022, 2023))</code></pre>
</section><section id="plotting-with-stminsights" class="slide level2">
<h2>Plotting with <code>stminsights</code></h2>
<p><img src="figures/unnamed-chunk-40-1.png" width="80%" /></p>
<aside class="notes">
<p>Alternatively, the <code>stminsights</code> package could be used to extract the same regression information from the <code>stm</code> effects object and create customized charts.</p>
</aside>
</section><section id="treatment-effect-preprint-server" class="slide level2">
<h2>‘Treatment’ effect: preprint server</h2>
<p><img data-src="figures/unnamed-chunk-41-1.png" /></p>
<aside class="notes">
<p>The model also incorporated the preprint server (<em>bioRxiv</em> and <em>medRxiv</em>) as a covariate. We hypothesized that the prevalence of certain topics will be influenced by this covariate, i.e. that we are more likely to see certain topics on either <em>bioRxiv</em> and <em>medRxiv</em>. STM interprets this as a <em>treatment</em> (see <span class="citation" data-cites="RobertsStewart_et_2014_AJPS_58">(Roberts et al. <a href="#/ref-RobertsStewart_et_2014_AJPS_58" role="doc-biblioref">2014</a>)</span> for background and examples) and we can extract the effect of this treatment from the regression object returned by <code>estimateEffect()</code>.</p>
<p>The <code>stm::plot()</code> offers different methods to explore those effects. The figure below lists the effect of <em>‘treatment medrxiv’</em> for all topics in the model. The treatment can have a positive or negative effect. Here we can for example see that Topic 4 (“mental health”) can be expected with higher prevalence in <em>medRxiv</em> preprints, whereas Topic 9 (“virus molecular structure”) will have a much lower prevalence in <em>medRxiv</em> preprints, i.e. should be expected with higher prevalence in <em>bioRxiv</em> preprints.</p>
</aside>
</section><section id="treatment-effect-preprint-server-1" class="slide level2">
<h2>‘Treatment’ effect: preprint server</h2>
<p><img data-src="figures/unnamed-chunk-42-1.png" /></p>
<aside class="notes">
<p>We can also compare the topical prevalence effect of covariate values for a single topic. The figure below confirms the previous observation for Topic 9 (“virus molecular structure”) which has a prevalence close to zero in <em>medRxiv</em> preprints but a prevalence of approximately 0.17 for <em>bioRxiv</em> preprints, i.e. it seems to appear almost exclusively in the latter.</p>
</aside>
</section><section id="combination-of-preprint-server-and-publication-year" class="slide level2">
<h2>Combination of preprint server and publication year</h2>
<p><img src="figures/unnamed-chunk-43-1.png" width="70%" /></p>
<aside class="notes">
<p>Finally, we can also explore the combined effect of covariates; we assumed an interacting effect of the two covariates <code>server</code> and <code>year</code>. The plot below visualizes this for Topic 17 (“virus variants”) and illustrates that the topical prevalence increased throughout the pandemic in all preprints but that the topic apparently received more coverage in <em>bioRxiv</em> preprints.</p>
</aside>
</section><section id="using-stminsight" class="slide level2">
<h2>Using <code>stminsight</code></h2>
<p><img src="figures/unnamed-chunk-44-1.png" width="80%" /></p>
<aside class="notes">
<p>Again, <code>stminsights</code> can be used to retrieve this information and create customized visualizations for the combined covariate effect.</p>
</aside>
</section><section id="exploring-the-topic-structure" class="slide level2">
<h2>Exploring the topic structure</h2>
</section><section id="topic-correlations" class="slide level2">
<h2>Topic correlations</h2>
<pre class="r"><code>covid_topic_correlations &lt;- topicCorr(covid_model_K20)
plot(covid_topic_correlations)</code></pre>
<p><img src="figures/unnamed-chunk-45-1.png" width="80%" /></p>
<aside class="notes">
<p>Finally, considering that STM is extending <span class="citation" data-cites="RobertsStewart_et_2019_JSTATS_91">(Roberts, Stewart, and Tingley <a href="#/ref-RobertsStewart_et_2019_JSTATS_91" role="doc-biblioref">2019</a>)</span> a correlated topic model <span class="citation" data-cites="BleiLafferty2007_AAS_1">(Blei and Lafferty <a href="#/ref-BleiLafferty2007_AAS_1" role="doc-biblioref">2007</a>)</span> we may also explore if topics are frequently cooccuring. A a topic correlation matrix is retrieved with <code>stm::topicCorr()</code> which can then be plotted. The resulting figure below indicates at least two clusters of topics.</p>
</aside>
</section><section id="network-analysis-of-topics" class="slide level2">
<h2>Network analysis of topics</h2>
<div class="fig-container" data-file="topic_correlation.html">

</div>
<aside class="notes">
<p>The correlation matrix can be used for further analysis (e.g. networks and clusters) or alternative visualizations. Both are outside the scope of this example and the course module. For illustration, the following figure creates an alternative network visualization, with nodes colored according to a community analysis of the topical network, which here reveals four distinct topical clusters.</p>
</aside>
</section></section>
<section><section id="exercises" class="title-slide slide level1"><h1>Exercises</h1></section><section id="exploring-biodiversity-preprints" class="slide level2">
<h2>Exploring biodiversity preprints</h2>
<ul>
<li>Create a subset of preprints referencing “biodiversity”; fit a topic model with 10 topics and explore the interacting effect of covariates <code>is_published</code> and <code>year</code> (not <code>s(year)</code>).</li>
</ul>
</section></section>
<section><section id="thank-you" class="title-slide slide level1"><h1>Thank You!</h1></section><section id="key-resources" class="slide level2">
<h2>Key Resources</h2>
<ul>
<li><a href="http://quanteda.io/">quanteda R package</a></li>
<li><a href="https://www.jstatsoft.org/article/view/v091i02">stm: An R Package for Structural Topic Models</a> <span class="citation" data-cites="RobertsStewart_et_2019_JSTATS_91">(Roberts, Stewart, and Tingley <a href="#/ref-RobertsStewart_et_2019_JSTATS_91" role="doc-biblioref">2019</a>)</span></li>
<li><a href="https://github.com/chainsawriot/oolong">oolong R package</a></li>
</ul>
</section><section id="references" class="slide level2 top-aligned-slide">
<h2>References</h2>
<div id="refs" role="doc-bibliography">
<div id="ref-Blei2012_COMMACM_55">
<p>Blei, David. 2012. “Probabilistic Topic Models.” <em>Communications of the ACM</em> 55 (4): 77–84. <a href="https://doi.org/10.1145/2133806.2133826">https://doi.org/10.1145/2133806.2133826</a>.</p>
</div>
<div id="ref-BleiLafferty2007_AAS_1">
<p>Blei, David M., and John D. Lafferty. 2007. “A Correlated Topic Model of Science.” <em>The Annals of Applied Statistics</em> 1 (1): 17–35.</p>
</div>
<div id="ref-BleiNgEt2003_JMLR_3">
<p>Blei, David M., Andrew Y. Ng, and Michael I. Jordan. 2003. “Latent Dirichlet Allocation.” <em>The Journal of Machine Learning Research</em> 3 (March): 993–1022.</p>
</div>
<div id="ref-CallaghanMinx_et_2020_NCC_10">
<p>Callaghan, Max W., Jan C. Minx, and Piers M. Forster. 2020. “A Topography of Climate Change Research.” <em>Nature Climate Change</em> 10 (2): 118–23. <a href="https://doi.org/10.1038/s41558-019-0684-5">https://doi.org/10.1038/s41558-019-0684-5</a>.</p>
</div>
<div id="ref-DaumeAlbertEt2014_FORESTECOSYST_1">
<p>Daume, Stefan, Matthias Albert, and Klaus von Gadow. 2014. “Assessing Citizen Science Opportunities in Forest Monitoring Using Probabilistic Topic Modelling.” <em>Forest Ecosystems</em> 1 (1): 11. <a href="https://doi.org/10.1186/s40663-014-0011-6">https://doi.org/10.1186/s40663-014-0011-6</a>.</p>
</div>
<div id="ref-DennySpirling_2018_PA_26">
<p>Denny, Matthew J., and Arthur Spirling. 2018. “Text Preprocessing for Unsupervised Learning: Why It Matters, When It Misleads, and What to Do About It.” <em>Political Analysis</em> 26 (2): 168–89. <a href="https://doi.org/10.1017/pan.2017.44">https://doi.org/10.1017/pan.2017.44</a>.</p>
</div>
<div id="ref-Farell_2016_PNAS_113">
<p>Farrell, Justin. 2016. “Corporate Funding and Ideological Polarization About Climate Change.” <em>Proceedings of the National Academy of Sciences of the United States of America</em> 113 (1): 92–97. <a href="https://doi.org/10.1073/pnas.1509433112">https://doi.org/10.1073/pnas.1509433112</a>.</p>
</div>
<div id="ref-PovitkinaCarlssonJagers_et_2021_GEC_70">
<p>Povitkina, Marina, Sverker Carlsson Jagers, Simon Matti, and Johan Martinsson. 2021. “Why Are Carbon Taxes Unfair? Disentangling Public Perceptions of Fairness.” <em>Global Environmental Change</em> 70 (September): 102356. <a href="https://doi.org/10.1016/j.gloenvcha.2021.102356">https://doi.org/10.1016/j.gloenvcha.2021.102356</a>.</p>
</div>
<div id="ref-RobertsStewart_et_2019_JSTATS_91">
<p>Roberts, Margaret E., Brandon M. Stewart, and Dustin Tingley. 2019. “Stm: An R Package for Structural Topic Models.” <em>Journal of Statistical Software</em> 91 (1): 1–40. <a href="https://doi.org/10.18637/jss.v091.i02">https://doi.org/10.18637/jss.v091.i02</a>.</p>
</div>
<div id="ref-RobertsStewart_et_2014_AJPS_58">
<p>Roberts, Margaret E., Brandon M. Stewart, Dustin Tingley, Christopher Lucas, Jetson Leder-Luis, Shana Kushner Gadarian, Bethany Albertson, and David G. Rand. 2014. “Structural Topic Models for Open-Ended Survey Responses.” <em>American Journal of Political Science</em> 58 (4): 1064–82. <a href="https://doi.org/10.1111/ajps.12103">https://doi.org/10.1111/ajps.12103</a>.</p>
</div>
<div id="ref-SzekelyBrocke_2017_PO_12">
<p>Székely, Nadine, and Jan vom Brocke. 2017. “What Can We Learn from Corporate Sustainability Reporting? Deriving Propositions for Research and Practice from over 9,500 Corporate Sustainability Reports Published Between 1999 and 2015 Using Topic Modelling Technique.” <em>PLOS ONE</em> 12 (4): e0174807. <a href="https://doi.org/10.1371/journal.pone.0174807">https://doi.org/10.1371/journal.pone.0174807</a>.</p>
</div>
</div>
</section><section id="colophon" class="slide level2 colophon">
<h2>Colophon</h2>
<p><strong>“Structural Topic Modeling with R”</strong> by <em>Stefan Daume</em></p>
<p> </p>
<p>Presented at DS4SD SRC R course on 11. April 2025.</p>
<p> </p>
<p>This presentation can be cited using: <em>doi:…</em></p>
<p> </p>
<p><strong>PRESENTATION DETAILS</strong></p>
<p><strong>Author/Affiliation:</strong> Stefan Daume, Stockholm Resilience Centre, Stockholm University</p>
<p><strong>Presentation URL:</strong> <a href="https://sdaume.github.io/ds4sd-2024-modules/topicmodels/slides/" class="uri">https://sdaume.github.io/ds4sd-2024-modules/topicmodels/slides/</a></p>
<p><strong>Presentation Source:</strong> [TBD]</p>
<p><strong>Presentation PDF:</strong> [TBD]</p>
<p> </p>
<p><strong>CREDITS &amp; LICENSES</strong></p>
<p>This presentation is delivered with the help of several free and open source tools and libraries. It utilises the <a href="https://revealjs.com/">reveal.js</a> presentation framework and has been created using <a href="https://rmarkdown.rstudio.com">RMarkdown</a>, <a href="https://yihui.name/knitr/">knitr</a>, <a href="https://www.rstudio.com">RStudio</a> and <a href="https://pandoc.org/">Pandoc</a>. <a href="https://highlightjs.org">highlight.js</a> provides syntax highlighting for code sections. <a href="https://www.mathjax.org">MathJax</a> supports the rendering of mathematical notations. PDF and JPG copies of this presentation were generated with <a href="https://github.com/astefanutti/decktape">DeckTape</a>. Please note the respective licenses of these tools and libraries.</p>
<p> </p>
<p>If not noted and attributed otherwise, the contents (text, charts, images) of this presentation are <strong>Copyright © 2025 of the Author</strong> and provided under a <em>CC BY 4.0</em> public domain license.</p>
</section></section>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>NOTE we use the recommended spline function for the <code>year</code> variable. Consult the STM documentation for details on this.<a href="#/fnref1" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn2" role="doc-endnote"><p>NOTE that for each document a non-zero probability for all topics is assigned.<a href="#/fnref2" class="footnote-back" role="doc-backlink">↩</a></p></li>
</ol>
</section>
    </div>
  </div>

  <script src="./reveal.js-3.6.0/lib/js/head.min.js"></script>
  <script src="./reveal.js-3.6.0/js/reveal.js"></script>
  <script src="http://d3js.org/d3.v3.min.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        math: {
          mathjax: './MathJax-2.7.5/MathJax.js',
          config: 'TeX-MML-AM_SVG-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: './reveal.js-3.6.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: './reveal.js-3.6.0/plugin/zoom-js/zoom.js', async: true },
          { src: './reveal.js-3.6.0/plugin/math/math.js', async: true },
          { src: './reveal.js-3.6.0/plugin/notes/notes.js', async: true },
          { src: './reveal.js-3.6.0/plugin/reveald3/reveald3.js', async: true }
        ]
      });
    </script>
    </body>
</html>
